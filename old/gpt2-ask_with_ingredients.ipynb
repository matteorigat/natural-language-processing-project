{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-25T15:08:31.158207Z",
     "start_time": "2025-04-25T15:08:31.153333Z"
    }
   },
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from rouge import Rouge\n",
    "import torch\n",
    "import csv\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import BertModel, BertTokenizer\n"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T15:08:31.176834Z",
     "start_time": "2025-04-25T15:08:31.173848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "saved_model = \"models/colab_model_ingredients_epochs_2\"\n",
    "model_name = \"gpt2\""
   ],
   "id": "2887c735014ffaa6",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T15:08:31.415431Z",
     "start_time": "2025-04-25T15:08:31.205058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the GPT tokenizer.\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name, bos_token='[BOS]', eos_token='[EOS]', pad_token='[PAD]')\n",
    "# add special tokens for title, ingredients and instruction seperator\n",
    "special_tokens_dict = {'additional_special_tokens': ['[INGREDIENTS]', '[TECHNIQUES]', '[STEPS]']}  # '[INGR]',  '[STEP]'\n",
    "# check the number of special tokens\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "print('We have added', num_added_toks, 'tokens')"
   ],
   "id": "ca1255941f36fbb1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 3 tokens\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T15:08:31.618550Z",
     "start_time": "2025-04-25T15:08:31.419661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the trained GPT-2 model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained(saved_model)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Ensure the model is on the right device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ],
   "id": "165285e2cfc6ebef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50263, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50263, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T15:08:31.636119Z",
     "start_time": "2025-04-25T15:08:31.632982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_recipe(ingredients, techniques, model, tokenizer, max_length=820, temperature=0.5, top_k=50, top_p=0.5):\n",
    "    #ingredients = ingredients.split(', ')\n",
    "    #ingredients_str = ''.join([f\"[INGR]{ingr}\" for ingr in ingredients])\n",
    "    input_text = '[BOS][INGREDIENTS]' + ingredients +'[TECHNIQUES]'+ techniques +'[STEPS]'\n",
    "    input_ids = tokenizer(input_text, return_tensors='pt').input_ids.to(device)\n",
    "    \n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        temperature=temperature, # Lower values make the model more confident (less random), while higher values increase randomness.\n",
    "        top_k=top_k,  #Increase to consider more tokens, decrease to restrict the model’s choices.\n",
    "        top_p=top_p,  # Increase to allow more diversity, decrease to make the model more conservative.\n",
    "        num_beams=3,\n",
    "        no_repeat_ngram_size=5,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True\n",
    "    )\n",
    "    \n",
    "    recipe = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "    \n",
    "    # Replace lowercase special tokens with uppercase\n",
    "    recipe = recipe.replace('[bos]', '[BOS]').replace('[ingredients]', '[INGREDIENTS]').replace('[techniques]', '[TECHNIQUES]').replace('[steps]', '[STEPS]').replace('[eos]', '[EOS]')\n",
    "    \n",
    "    #recipe = recipe.split('[EOS]', 1)[0] + '[EOS]'\n",
    "        \n",
    "    return recipe"
   ],
   "id": "3dce51f769144fd4",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T15:08:31.652854Z",
     "start_time": "2025-04-25T15:08:31.650233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_highlighted(generated_recipe, ingredients, techniques):\n",
    "    recipe=generated_recipe\n",
    "    ingredients_list = [ing.strip().lower() for ing in ingredients.split(',')]\n",
    "    for ingredient in ingredients_list:\n",
    "        recipe = recipe.replace(ingredient, f'\\033[91m{ingredient}\\033[0m')\n",
    "    \n",
    "    techniques_list = [tech.strip().lower() for tech in techniques.split(',')]\n",
    "    for technique in techniques_list:\n",
    "        recipe = recipe.replace(technique, f'\\033[92m{technique}\\033[0m')\n",
    "\n",
    "    return recipe"
   ],
   "id": "14db32a328345733",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T15:53:03.129473Z",
     "start_time": "2025-04-25T15:52:57.549788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "ingredients = \"tomato puree, lemon juice, salt, oregano, basil, thyme, garlic powder\"\n",
    "\n",
    "techniques = \"distill, caramelize, saute\"\n",
    "\n",
    "generated_recipe = generate_recipe(ingredients, techniques, model, tokenizer)\n",
    "    \n",
    "print(print_highlighted(generated_recipe, ingredients, techniques))\n",
    "print(\"\\n\", len(generated_recipe) - len(ingredients))"
   ],
   "id": "2e215ecde86eeb55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BOS] [INGREDIENTS] \u001B[91mtomato puree\u001B[0m, \u001B[91mlemon juice\u001B[0m, \u001B[91msalt\u001B[0m, \u001B[91moregano\u001B[0m, \u001B[91mbasil\u001B[0m, \u001B[91mthyme\u001B[0m, \u001B[91mgarlic powder\u001B[0m [TECHNIQUES] \u001B[92mpressure cook\u001B[0m, \u001B[92mstew\u001B[0m, \u001B[92msaute\u001B[0m [STEPS]  \u001B[92mpressure cook\u001B[0m, \u001B[91mlemon juice\u001B[0m, clove[TECHNIQUES]boil, combine, simmer, skillet, thicken[STEPS]in a large skillet, heat the butter over medium heat, add the garlic and \u001B[92msaute\u001B[0m until fragrant, about 5 minutes, add the onion and \u001B[92msaute\u001B[0m for 2 minutes, add the \u001B[91mtomato puree\u001B[0m, \u001B[91msalt\u001B[0m, pepper, \u001B[91moregano\u001B[0m, \u001B[91mbasil\u001B[0m, \u001B[91mthyme\u001B[0m, and \u001B[91mgarlic powder\u001B[0m, bring to a boil, reduce the heat to low and simmer for 10 minutes, add the \u001B[92mstew\u001B[0med tomatoes and simmer for 5 minutes, stir in the \u001B[91mlemon juice\u001B[0m, season with \u001B[91msalt\u001B[0m and pepper to taste[EOS][PAD][PAD][PAD][PAD][PAD][EOS]\n",
      "\n",
      " 603\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T15:08:23.222633Z",
     "start_time": "2025-04-25T15:06:43.868977Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "334df9a0846b0eb4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate the generated recipe",
   "id": "2e1f60401ab845db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T15:08:23.233902Z",
     "start_time": "2025-04-25T15:06:43.891517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load and also preprocess the raw data\n",
    "def load_preprocess_raw_data(raw_data):\n",
    "    recipe_instances = []\n",
    "\n",
    "    with open(raw_data, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            # Extract relevant fields from CSV row\n",
    "            #name = row['name'].lower().replace('\"', '')  # Remove any extra quotes\n",
    "            ingredients = row['ingredients'].lower().replace('\\'', '').replace('[', '').replace(']', '')\n",
    "            instructions = row['steps'].lower().replace('\\'', '').replace('[', '').replace(']', '')\n",
    "\n",
    "            # Prepare recipe instance string\n",
    "            recipe_instance = '[BOS]' + ingredients + '[STEPS]' + instructions + '[EOS]'  #+name+'[INGREDIENTS]'\n",
    "\n",
    "            # Limit length to 2000 characters as per your function\n",
    "            if len(recipe_instance) <= 3000:\n",
    "                recipe_instances.append(recipe_instance)\n",
    "\n",
    "    return recipe_instances"
   ],
   "id": "dc8f49e07f4f214d",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T15:08:23.236550Z",
     "start_time": "2025-04-25T15:06:43.929630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create text list for dataset\n",
    "# https://www.kaggle.com/datasets/shuyangli94/food-com-recipes-and-user-interactions/data\n",
    "recipe_list = load_preprocess_raw_data(\"dataset/RAW_merged_top_smallest.csv\")\n",
    "recipe_list = random.sample(recipe_list, int(0.1 * len(recipe_list)))"
   ],
   "id": "fa0dfde3c3812d48",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T15:08:23.236971Z",
     "start_time": "2025-04-25T15:06:43.992406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize models and tokenizers\n",
    "model_name_bert = 'bert-base-uncased'\n",
    "tokenizer_bert = BertTokenizer.from_pretrained(model_name_bert)\n",
    "model_bert = BertModel.from_pretrained(model_name_bert)\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "\n",
    "# Function to calculate ROUGE-L F1 score\n",
    "def calculate_rouge_score(text1, text2):\n",
    "    scores = rouge.get_scores(text1, text2)\n",
    "    rouge_l_f1 = scores[0]['rouge-l']['f']\n",
    "    return rouge_l_f1\n",
    "\n",
    "\n",
    "# Function to get GPT-2 embeddings\n",
    "def get_gpt2_embedding(text, model, tokenizer):\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    hidden_states = outputs[0]\n",
    "    pooled_embedding = torch.mean(hidden_states, dim=1)\n",
    "    return pooled_embedding\n",
    "\n",
    "\n",
    "# Function to calculate cosine similarity for GPT-2 embeddings\n",
    "def calculate_gpt2_similarity(text1, text2, model, tokenizer):\n",
    "    embedding1 = get_gpt2_embedding(text1, model, tokenizer)\n",
    "    embedding2 = get_gpt2_embedding(text2, model, tokenizer)\n",
    "    similarity = cosine_similarity(embedding1, embedding2).item()\n",
    "    return similarity\n",
    "\n",
    "\n",
    "# Function to encode text for BERT\n",
    "def encode_text(text, tokenizer):\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt', max_length=512, truncation=True)\n",
    "    return input_ids\n",
    "\n",
    "\n",
    "# Function to calculate BERT embeddings\n",
    "def get_bert_embedding(input_ids, model):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        pooled_embedding = torch.mean(last_hidden_state, dim=1)\n",
    "    return pooled_embedding\n",
    "\n",
    "\n",
    "# Function to calculate cosine similarity for BERT embeddings\n",
    "def calculate_bert_similarity(text1, text2, model, tokenizer):\n",
    "    input1 = encode_text(text1, tokenizer)\n",
    "    input2 = encode_text(text2, tokenizer)\n",
    "    embedding1 = get_bert_embedding(input1, model)\n",
    "    embedding2 = get_bert_embedding(input2, model)\n",
    "    similarity = cosine_similarity(embedding1.cpu(), embedding2.cpu()).item()\n",
    "    return similarity\n",
    "\n",
    "\n",
    "# Function to evaluate generated recipe against a list of real recipes\n",
    "def evaluate_generated_recipe(generated_recipe, real_recipes):\n",
    "    rouge_scores = []\n",
    "    gpt2_similarities = []\n",
    "    bert_similarities = []\n",
    "\n",
    "    for real_recipe in tqdm(real_recipes, desc=\"Evaluating recipes\"):\n",
    "        rouge_score = calculate_rouge_score(generated_recipe, real_recipe)\n",
    "        gpt2_similarity = calculate_gpt2_similarity(generated_recipe, real_recipe, model, tokenizer)\n",
    "        bert_similarity = calculate_bert_similarity(generated_recipe, real_recipe, model_bert, tokenizer_bert)\n",
    "\n",
    "        rouge_scores.append(rouge_score)\n",
    "        gpt2_similarities.append(gpt2_similarity)\n",
    "        bert_similarities.append(bert_similarity)\n",
    "\n",
    "    # Calculate average scores\n",
    "    avg_scores = [(sum(scores) / len(scores)) for scores in zip(rouge_scores)]\n",
    "    #, gpt2_similarities, bert_similarities\n",
    "\n",
    "    # Find index of recipe with maximum average score\n",
    "    max_index = avg_scores.index(max(avg_scores))\n",
    "\n",
    "    return real_recipes[max_index], rouge_scores[max_index], gpt2_similarities[max_index], bert_similarities[max_index]"
   ],
   "id": "f6c97dbc2dd3d3c5",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T15:08:23.239603Z",
     "start_time": "2025-04-25T15:06:46.027361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_recipe = evaluate_generated_recipe(generated_recipe, recipe_list)\n",
    "\n",
    "print(\"Generated Recipe:\")\n",
    "print(print_highlighted(generated_recipe, ingredients))\n",
    "print(\"\\nMost Similar Real Recipe:\")\n",
    "print(print_highlighted(best_recipe[0], ingredients), \"\\n\\nrouge-l f1:\", best_recipe[1], \"\\nGPT-2 similarity:\",\n",
    "      best_recipe[2], \"\\nBERT similarity:\", best_recipe[3])"
   ],
   "id": "ce011dff65770dc4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating recipes:   7%|▋         | 43/601 [00:16<03:39,  2.54it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m best_recipe \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_generated_recipe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgenerated_recipe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrecipe_list\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGenerated Recipe:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(print_highlighted(generated_recipe, ingredients, techniques))\n",
      "Cell \u001B[0;32mIn[26], line 67\u001B[0m, in \u001B[0;36mevaluate_generated_recipe\u001B[0;34m(generated_recipe, real_recipes)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m real_recipe \u001B[38;5;129;01min\u001B[39;00m tqdm(real_recipes, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEvaluating recipes\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     66\u001B[0m     rouge_score \u001B[38;5;241m=\u001B[39m calculate_rouge_score(generated_recipe, real_recipe)\n\u001B[0;32m---> 67\u001B[0m     gpt2_similarity \u001B[38;5;241m=\u001B[39m \u001B[43mcalculate_gpt2_similarity\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgenerated_recipe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreal_recipe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     68\u001B[0m     bert_similarity \u001B[38;5;241m=\u001B[39m calculate_bert_similarity(generated_recipe, real_recipe, model_bert, tokenizer_bert)\n\u001B[1;32m     70\u001B[0m     rouge_scores\u001B[38;5;241m.\u001B[39mappend(rouge_score)\n",
      "Cell \u001B[0;32mIn[26], line 28\u001B[0m, in \u001B[0;36mcalculate_gpt2_similarity\u001B[0;34m(text1, text2, model, tokenizer)\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcalculate_gpt2_similarity\u001B[39m(text1, text2, model, tokenizer):\n\u001B[0;32m---> 28\u001B[0m     embedding1 \u001B[38;5;241m=\u001B[39m \u001B[43mget_gpt2_embedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m     embedding2 \u001B[38;5;241m=\u001B[39m get_gpt2_embedding(text2, model, tokenizer)\n\u001B[1;32m     30\u001B[0m     similarity \u001B[38;5;241m=\u001B[39m cosine_similarity(embedding1, embedding2)\u001B[38;5;241m.\u001B[39mitem()\n",
      "Cell \u001B[0;32mIn[26], line 20\u001B[0m, in \u001B[0;36mget_gpt2_embedding\u001B[0;34m(text, model, tokenizer)\u001B[0m\n\u001B[1;32m     18\u001B[0m input_ids \u001B[38;5;241m=\u001B[39m tokenizer\u001B[38;5;241m.\u001B[39mencode(text, return_tensors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m---> 20\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     22\u001B[0m pooled_embedding \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmean(hidden_states, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/torch/nn/modules/module.py:1657\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1655\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1656\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1657\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/torch/nn/modules/module.py:1675\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1663\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1664\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1665\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\n\u001B[1;32m   1666\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks\n\u001B[1;32m   1667\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1673\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks\n\u001B[1;32m   1674\u001B[0m ):\n\u001B[0;32m-> 1675\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1677\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1678\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:1305\u001B[0m, in \u001B[0;36mGPT2LMHeadModel.forward\u001B[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1297\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1298\u001B[0m \u001B[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001B[39;00m\n\u001B[1;32m   1299\u001B[0m \u001B[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001B[39;00m\n\u001B[1;32m   1300\u001B[0m \u001B[38;5;124;03m    `labels = input_ids` Indices are selected in `[-100, 0, ..., config.vocab_size]` All labels set to `-100`\u001B[39;00m\n\u001B[1;32m   1301\u001B[0m \u001B[38;5;124;03m    are ignored (masked), the loss is only computed for labels in `[0, ..., config.vocab_size]`\u001B[39;00m\n\u001B[1;32m   1302\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1303\u001B[0m return_dict \u001B[38;5;241m=\u001B[39m return_dict \u001B[38;5;28;01mif\u001B[39;00m return_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39muse_return_dict\n\u001B[0;32m-> 1305\u001B[0m transformer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1306\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1307\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1308\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1309\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtoken_type_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1310\u001B[0m \u001B[43m    \u001B[49m\u001B[43mposition_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mposition_ids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1311\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1312\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs_embeds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1313\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1314\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1315\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1316\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1317\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1318\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1319\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1320\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m transformer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1322\u001B[0m \u001B[38;5;66;03m# Set device for model parallelism\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/torch/nn/modules/module.py:1657\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1655\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1656\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1657\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/torch/nn/modules/module.py:1675\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1663\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1664\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1665\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\n\u001B[1;32m   1666\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks\n\u001B[1;32m   1667\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1673\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks\n\u001B[1;32m   1674\u001B[0m ):\n\u001B[0;32m-> 1675\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1677\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1678\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:1119\u001B[0m, in \u001B[0;36mGPT2Model.forward\u001B[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1107\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[1;32m   1108\u001B[0m         block\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m,\n\u001B[1;32m   1109\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1116\u001B[0m         output_attentions,\n\u001B[1;32m   1117\u001B[0m     )\n\u001B[1;32m   1118\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1119\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mblock\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1120\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1121\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_past\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer_past\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1122\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1123\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1124\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1125\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1126\u001B[0m \u001B[43m        \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1127\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1128\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1130\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/torch/nn/modules/module.py:1657\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1655\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1656\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1657\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/torch/nn/modules/module.py:1675\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1663\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1664\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1665\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\n\u001B[1;32m   1666\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks\n\u001B[1;32m   1667\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1673\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks\n\u001B[1;32m   1674\u001B[0m ):\n\u001B[0;32m-> 1675\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1677\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1678\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:617\u001B[0m, in \u001B[0;36mGPT2Block.forward\u001B[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001B[0m\n\u001B[1;32m    615\u001B[0m residual \u001B[38;5;241m=\u001B[39m hidden_states\n\u001B[1;32m    616\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mln_1(hidden_states)\n\u001B[0;32m--> 617\u001B[0m attn_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    618\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    619\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlayer_past\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlayer_past\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    620\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    621\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    622\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    623\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    624\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    625\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m attn_outputs[\u001B[38;5;241m0\u001B[39m]  \u001B[38;5;66;03m# output_attn: a, present, (attentions)\u001B[39;00m\n\u001B[1;32m    626\u001B[0m outputs \u001B[38;5;241m=\u001B[39m attn_outputs[\u001B[38;5;241m1\u001B[39m:]\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/torch/nn/modules/module.py:1657\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1655\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1656\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1657\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/torch/nn/modules/module.py:1675\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1663\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1664\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1665\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\n\u001B[1;32m   1666\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks\n\u001B[1;32m   1667\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1673\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks\n\u001B[1;32m   1674\u001B[0m ):\n\u001B[0;32m-> 1675\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1677\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1678\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/transformers/models/gpt2/modeling_gpt2.py:328\u001B[0m, in \u001B[0;36mGPT2Attention.forward\u001B[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001B[0m\n\u001B[1;32m    326\u001B[0m     attention_mask \u001B[38;5;241m=\u001B[39m encoder_attention_mask\n\u001B[1;32m    327\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 328\u001B[0m     query, key, value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mc_attn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msplit_size, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m    330\u001B[0m query \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_split_heads(query, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_heads, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhead_dim)\n\u001B[1;32m    331\u001B[0m key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_split_heads(key, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_heads, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhead_dim)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/torch/nn/modules/module.py:1657\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1655\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1656\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1657\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/torch/nn/modules/module.py:1675\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1663\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1664\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1665\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\n\u001B[1;32m   1666\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks\n\u001B[1;32m   1667\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1673\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks\n\u001B[1;32m   1674\u001B[0m ):\n\u001B[0;32m-> 1675\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1677\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1678\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/transformers/pytorch_utils.py:103\u001B[0m, in \u001B[0;36mConv1D.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    101\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m    102\u001B[0m     size_out \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39msize()[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m+\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnf,)\n\u001B[0;32m--> 103\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maddmm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mview\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    104\u001B[0m     x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39mview(size_out)\n\u001B[1;32m    105\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T15:08:23.240117Z",
     "start_time": "2025-04-25T15:03:23.789218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# Function to extract ingredients from a recipe\n",
    "def extract_ingredients(recipe):\n",
    "    start = recipe.find('[BOS]') + len('[BOS]')\n",
    "    end = recipe.find('[STEPS]')\n",
    "    ingredients = recipe[start:end].strip()\n",
    "    return ingredients\n",
    "\n",
    "\n",
    "# Function to calculate cosine similarity for ingredient lists\n",
    "def calculate_ingredient_similarity(ingredients1, ingredients2):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([ingredients1, ingredients2])\n",
    "    vectors = vectorizer.toarray()\n",
    "    cosine_sim = cosine_similarity(vectors)\n",
    "    return cosine_sim[0, 1]\n",
    "\n",
    "\n",
    "# Function to evaluate generated recipe against a list of real recipes\n",
    "def evaluate_generated_recipe_by_ingredients(generated_recipe, real_recipes, top_k=5):\n",
    "    generated_ingredients = extract_ingredients(generated_recipe)\n",
    "\n",
    "    similarities = []\n",
    "    for real_recipe in tqdm(real_recipes, desc=\"Processing recipes\"):\n",
    "        real_ingredients = extract_ingredients(real_recipe)\n",
    "        similarity = calculate_ingredient_similarity(generated_ingredients, real_ingredients)\n",
    "        similarities.append((real_recipe, similarity))\n",
    "\n",
    "    # Sort recipes based on ingredient similarity\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get top k recipes\n",
    "    top_k_recipes = similarities[:top_k]\n",
    "\n",
    "    results = []\n",
    "    for real_recipe, sim in tqdm(top_k_recipes, desc=\"Calculating scores\"):\n",
    "        rouge_score = calculate_rouge_score(generated_recipe, real_recipe)\n",
    "        gpt2_similarity = calculate_gpt2_similarity(generated_recipe, real_recipe, model, tokenizer)\n",
    "        bert_similarity = calculate_bert_similarity(generated_recipe, real_recipe, model_bert, tokenizer_bert)\n",
    "        results.append((real_recipe, sim, rouge_score, gpt2_similarity, bert_similarity))\n",
    "\n",
    "    return results"
   ],
   "id": "802c02028ffee9c6",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T15:08:23.241953Z",
     "start_time": "2025-04-25T15:03:23.910298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate and print top k recipes\n",
    "top_k = 5\n",
    "top_k_recipes = evaluate_generated_recipe_by_ingredients(generated_recipe, recipe_list, top_k=top_k)\n",
    "\n",
    "for i, (recipe, ingredient_sim, rouge_score, gpt2_sim, bert_sim) in enumerate(top_k_recipes):\n",
    "    print(f\"\\nRecipe {i + 1} (Ingredient Similarity: {ingredient_sim:.2f}):\")\n",
    "    print(print_highlighted(recipe, ingredients))\n",
    "    print(f\"ROUGE-L F1: {rouge_score:.4f}\")\n",
    "    print(f\"GPT-2 Similarity: {gpt2_sim:.4f}\")\n",
    "    print(f\"BERT Similarity: {bert_sim:.4f}\")"
   ],
   "id": "199117df36eb1883",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing recipes: 100%|██████████| 601/601 [00:00<00:00, 1582.80it/s]\n",
      "Calculating scores: 100%|██████████| 5/5 [00:01<00:00,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recipe 1 (Ingredient Similarity: 0.32):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "print_highlighted() missing 1 required positional argument: 'techniques'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (recipe, ingredient_sim, rouge_score, gpt2_sim, bert_sim) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(top_k_recipes):\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mRecipe \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m (Ingredient Similarity: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mingredient_sim\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m):\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 7\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[43mprint_highlighted\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrecipe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mingredients\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mROUGE-L F1: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrouge_score\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGPT-2 Similarity: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mgpt2_sim\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: print_highlighted() missing 1 required positional argument: 'techniques'"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
