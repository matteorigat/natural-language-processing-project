{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-10T13:36:31.990096Z",
     "start_time": "2024-09-10T13:36:18.199397Z"
    }
   },
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from rouge import Rouge\n",
    "import torch\n",
    "import csv\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import BertModel, BertTokenizer"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x1072ce1b0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/matteorigat/PycharmProjects/nlp-project/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T13:36:31.995732Z",
     "start_time": "2024-09-10T13:36:31.992551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "saved_model = \"Models/colab_model_3\"\n",
    "model_name = \"gpt2\""
   ],
   "id": "9ad32890326697be",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T13:36:32.595793Z",
     "start_time": "2024-09-10T13:36:31.997481Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the GPT tokenizer.\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name, bos_token='[BOS]', eos_token='[EOS]', pad_token='[PAD]')\n",
    "# add special tokens for title, ingredients and instruction seperator\n",
    "special_tokens_dict = {'additional_special_tokens': ['[STEPS]']} #'[INGREDIENTS]', \n",
    "# check the number of special tokens\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "print('We have added', num_added_toks, 'tokens')"
   ],
   "id": "ca1255941f36fbb1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 1 tokens\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T13:36:33.422567Z",
     "start_time": "2024-09-10T13:36:32.597219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the trained GPT-2 model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained(saved_model)\n",
    "\n",
    "# Ensure the model is on the right device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ],
   "id": "165285e2cfc6ebef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50261, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50261, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T13:36:33.425956Z",
     "start_time": "2024-09-10T13:36:33.423390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_recipe(ingredients, model, tokenizer, max_length=300, temperature=0.1, top_k=50, top_p=0.1):\n",
    "    input_text = '[BOS]' + ingredients + '[STEPS]'\n",
    "    input_ids = tokenizer(input_text, return_tensors='pt').input_ids.to(device)\n",
    "    \n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        temperature=temperature, # Lower values make the model more confident (less random), while higher values increase randomness.\n",
    "        top_k=top_k,  #Increase to consider more tokens, decrease to restrict the model’s choices.\n",
    "        top_p=top_p,  # Increase to allow more diversity, decrease to make the model more conservative.\n",
    "        num_beams=5,\n",
    "        no_repeat_ngram_size=2,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True\n",
    "    )\n",
    "    \n",
    "    recipe = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "    \n",
    "    # Replace lowercase special tokens with uppercase\n",
    "    recipe = recipe.replace('[bos]', '[BOS]').replace('[steps]', '[STEPS]').replace('[eos]', '[EOS]')\n",
    "    \n",
    "    recipe = recipe.split('[EOS]', 1)[0] + '[EOS]'\n",
    "        \n",
    "    return recipe"
   ],
   "id": "3dce51f769144fd4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T13:36:33.429156Z",
     "start_time": "2024-09-10T13:36:33.427038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_highlighted(generated_recipe, ingredients):\n",
    "    recipe=generated_recipe\n",
    "    ingredients_list = [ing.strip().lower() for ing in ingredients.split(',')]\n",
    "    for ingredient in ingredients_list:\n",
    "        recipe = recipe.replace(ingredient, f'\\033[91m{ingredient}\\033[0m')\n",
    "    return recipe"
   ],
   "id": "14db32a328345733",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T13:36:48.735151Z",
     "start_time": "2024-09-10T13:36:33.429769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "ingredients = \"pasta, tomato, fish\"\n",
    "\n",
    "generated_recipe = generate_recipe(ingredients, model, tokenizer)\n",
    "    \n",
    "print(print_highlighted(generated_recipe, ingredients))\n",
    "print(\"\\n\", len(generated_recipe) - len(ingredients))"
   ],
   "id": "2e215ecde86eeb55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BOS]\u001B[91mpasta\u001B[0m, \u001B[91mtomato\u001B[0m, \u001B[91mfish\u001B[0m [STEPS], mozzarella cheese[STEPS]preheat oven to 400 degrees fahrenheit, spray a baking sheet with non-stick cooking spray, arrange \u001B[91mfish\u001B[0m in a single layer, sprinkle with salt and pepper, top with \u001B[91mtomato\u001B[0mes, onion, and cheese, bake for 15 to 20 minutes or until \u001B[91mfish\u001B[0m flakes easily with a fork[EOS]\n",
      "\n",
      " 301\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate the generated recipe",
   "id": "2e1f60401ab845db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T13:36:48.738607Z",
     "start_time": "2024-09-10T13:36:48.735935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load and also preprocess the raw data\n",
    "def load_preprocess_raw_data(raw_data):\n",
    "    recipe_instances = []\n",
    "\n",
    "    with open(raw_data, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            # Extract relevant fields from CSV row\n",
    "            #name = row['name'].lower().replace('\"', '')  # Remove any extra quotes\n",
    "            ingredients = row['ingredients'].lower().replace('\\'', '').replace('[', '').replace(']', '')\n",
    "            instructions = row['steps'].lower().replace('\\'', '').replace('[', '').replace(']', '')\n",
    "\n",
    "            # Prepare recipe instance string\n",
    "            recipe_instance = '[BOS]' + ingredients + '[STEPS]' + instructions + '[EOS]'  #+name+'[INGREDIENTS]'\n",
    "\n",
    "            # Limit length to 2000 characters as per your function\n",
    "            if len(recipe_instance) <= 3000:\n",
    "                recipe_instances.append(recipe_instance)\n",
    "\n",
    "    return recipe_instances"
   ],
   "id": "dc8f49e07f4f214d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T13:36:50.992986Z",
     "start_time": "2024-09-10T13:36:48.739691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create text list for dataset\n",
    "# https://www.kaggle.com/datasets/shuyangli94/food-com-recipes-and-user-interactions/data\n",
    "recipe_list = load_preprocess_raw_data(\"dataset/RAW_recipes.csv\")\n",
    "recipe_list = random.sample(recipe_list, int(0.01 * len(recipe_list)))"
   ],
   "id": "fa0dfde3c3812d48",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T13:36:52.575658Z",
     "start_time": "2024-09-10T13:36:50.994960Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize models and tokenizers\n",
    "model_name_bert = 'bert-base-uncased'\n",
    "tokenizer_bert = BertTokenizer.from_pretrained(model_name_bert)\n",
    "model_bert = BertModel.from_pretrained(model_name_bert)\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "\n",
    "# Function to calculate ROUGE-L F1 score\n",
    "def calculate_rouge_score(text1, text2):\n",
    "    scores = rouge.get_scores(text1, text2)\n",
    "    rouge_l_f1 = scores[0]['rouge-l']['f']\n",
    "    return rouge_l_f1\n",
    "\n",
    "\n",
    "# Function to get GPT-2 embeddings\n",
    "def get_gpt2_embedding(text, model, tokenizer):\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    hidden_states = outputs[0]\n",
    "    pooled_embedding = torch.mean(hidden_states, dim=1)\n",
    "    return pooled_embedding\n",
    "\n",
    "\n",
    "# Function to calculate cosine similarity for GPT-2 embeddings\n",
    "def calculate_gpt2_similarity(text1, text2, model, tokenizer):\n",
    "    embedding1 = get_gpt2_embedding(text1, model, tokenizer)\n",
    "    embedding2 = get_gpt2_embedding(text2, model, tokenizer)\n",
    "    similarity = cosine_similarity(embedding1, embedding2).item()\n",
    "    return similarity\n",
    "\n",
    "\n",
    "# Function to encode text for BERT\n",
    "def encode_text(text, tokenizer):\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt', max_length=512, truncation=True)\n",
    "    return input_ids\n",
    "\n",
    "\n",
    "# Function to calculate BERT embeddings\n",
    "def get_bert_embedding(input_ids, model):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        pooled_embedding = torch.mean(last_hidden_state, dim=1)\n",
    "    return pooled_embedding\n",
    "\n",
    "\n",
    "# Function to calculate cosine similarity for BERT embeddings\n",
    "def calculate_bert_similarity(text1, text2, model, tokenizer):\n",
    "    input1 = encode_text(text1, tokenizer)\n",
    "    input2 = encode_text(text2, tokenizer)\n",
    "    embedding1 = get_bert_embedding(input1, model)\n",
    "    embedding2 = get_bert_embedding(input2, model)\n",
    "    similarity = cosine_similarity(embedding1.cpu(), embedding2.cpu()).item()\n",
    "    return similarity\n",
    "\n",
    "\n",
    "# Function to evaluate generated recipe against a list of real recipes\n",
    "def evaluate_generated_recipe(generated_recipe, real_recipes):\n",
    "    rouge_scores = []\n",
    "    gpt2_similarities = []\n",
    "    bert_similarities = []\n",
    "\n",
    "    for real_recipe in tqdm(real_recipes, desc=\"Evaluating recipes\"):\n",
    "        rouge_score = calculate_rouge_score(generated_recipe, real_recipe)\n",
    "        gpt2_similarity = calculate_gpt2_similarity(generated_recipe, real_recipe, model, tokenizer)\n",
    "        bert_similarity = calculate_bert_similarity(generated_recipe, real_recipe, model_bert, tokenizer_bert)\n",
    "\n",
    "        rouge_scores.append(rouge_score)\n",
    "        gpt2_similarities.append(gpt2_similarity)\n",
    "        bert_similarities.append(bert_similarity)\n",
    "\n",
    "    # Calculate average scores\n",
    "    avg_scores = [(sum(scores) / len(scores)) for scores in zip(rouge_scores)]\n",
    "    #, gpt2_similarities, bert_similarities\n",
    "\n",
    "    # Find index of recipe with maximum average score\n",
    "    max_index = avg_scores.index(max(avg_scores))\n",
    "\n",
    "    return real_recipes[max_index], rouge_scores[max_index], gpt2_similarities[max_index], bert_similarities[max_index]"
   ],
   "id": "f6c97dbc2dd3d3c5",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T13:51:04.509250Z",
     "start_time": "2024-09-10T13:36:52.580021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_recipe = evaluate_generated_recipe(generated_recipe, recipe_list)\n",
    "\n",
    "print(\"Generated Recipe:\")\n",
    "print(print_highlighted(generated_recipe, ingredients))\n",
    "print(\"\\nMost Similar Real Recipe:\")\n",
    "print(print_highlighted(best_recipe[0], ingredients), \"\\n\\nrouge-l f1:\", best_recipe[1], \"\\nGPT-2 similarity:\",\n",
    "      best_recipe[2], \"\\nBERT similarity:\", best_recipe[3])"
   ],
   "id": "ce011dff65770dc4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating recipes: 100%|██████████| 2312/2312 [14:11<00:00,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Recipe:\n",
      "[BOS]\u001B[91mpasta\u001B[0m, \u001B[91mtomato\u001B[0m, \u001B[91mfish\u001B[0m [STEPS], mozzarella cheese[STEPS]preheat oven to 400 degrees fahrenheit, spray a baking sheet with non-stick cooking spray, arrange \u001B[91mfish\u001B[0m in a single layer, sprinkle with salt and pepper, top with \u001B[91mtomato\u001B[0mes, onion, and cheese, bake for 15 to 20 minutes or until \u001B[91mfish\u001B[0m flakes easily with a fork[EOS]\n",
      "\n",
      "Most Similar Real Recipe:\n",
      "[BOS]red snapper, butter, parsley, fresh ground pepper, oranges[STEPS]preheat oven to 400 f, place the \u001B[91mfish\u001B[0m in a large baking pan, dot each piece of \u001B[91mfish\u001B[0m well with butter and sprinkle with parsley and pepper, lay the orange slices over the \u001B[91mfish\u001B[0m, bake for 20 minutes, reduce heat to 350 f, , and bake for 20 minutes more or until the \u001B[91mfish\u001B[0m flakes at the touch of a fork[EOS] \n",
      "\n",
      "rouge-l f1: 0.39130434288516075 \n",
      "GPT-2 similarity: 0.9997220635414124 \n",
      "BERT similarity: 0.9518119096755981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T13:51:04.567549Z",
     "start_time": "2024-09-10T13:51:04.510658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# Function to extract ingredients from a recipe\n",
    "def extract_ingredients(recipe):\n",
    "    start = recipe.find('[BOS]') + len('[BOS]')\n",
    "    end = recipe.find('[STEPS]')\n",
    "    ingredients = recipe[start:end].strip()\n",
    "    return ingredients\n",
    "\n",
    "\n",
    "# Function to calculate cosine similarity for ingredient lists\n",
    "def calculate_ingredient_similarity(ingredients1, ingredients2):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([ingredients1, ingredients2])\n",
    "    vectors = vectorizer.toarray()\n",
    "    cosine_sim = cosine_similarity(vectors)\n",
    "    return cosine_sim[0, 1]\n",
    "\n",
    "\n",
    "# Function to evaluate generated recipe against a list of real recipes\n",
    "def evaluate_generated_recipe_by_ingredients(generated_recipe, real_recipes, top_k=5):\n",
    "    generated_ingredients = extract_ingredients(generated_recipe)\n",
    "\n",
    "    similarities = []\n",
    "    for real_recipe in tqdm(real_recipes, desc=\"Processing recipes\"):\n",
    "        real_ingredients = extract_ingredients(real_recipe)\n",
    "        similarity = calculate_ingredient_similarity(generated_ingredients, real_ingredients)\n",
    "        similarities.append((real_recipe, similarity))\n",
    "\n",
    "    # Sort recipes based on ingredient similarity\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get top k recipes\n",
    "    top_k_recipes = similarities[:top_k]\n",
    "\n",
    "    results = []\n",
    "    for real_recipe, sim in tqdm(top_k_recipes, desc=\"Calculating scores\"):\n",
    "        rouge_score = calculate_rouge_score(generated_recipe, real_recipe)\n",
    "        gpt2_similarity = calculate_gpt2_similarity(generated_recipe, real_recipe, model, tokenizer)\n",
    "        bert_similarity = calculate_bert_similarity(generated_recipe, real_recipe, model_bert, tokenizer_bert)\n",
    "        results.append((real_recipe, sim, rouge_score, gpt2_similarity, bert_similarity))\n",
    "\n",
    "    return results"
   ],
   "id": "802c02028ffee9c6",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T13:51:06.999221Z",
     "start_time": "2024-09-10T13:51:04.568348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluate and print top k recipes\n",
    "top_k = 5\n",
    "top_k_recipes = evaluate_generated_recipe_by_ingredients(generated_recipe, recipe_list, top_k=top_k)\n",
    "\n",
    "for i, (recipe, ingredient_sim, rouge_score, gpt2_sim, bert_sim) in enumerate(top_k_recipes):\n",
    "    print(f\"\\nRecipe {i + 1} (Ingredient Similarity: {ingredient_sim:.2f}):\")\n",
    "    print(print_highlighted(recipe, ingredients))\n",
    "    print(f\"ROUGE-L F1: {rouge_score:.4f}\")\n",
    "    print(f\"GPT-2 Similarity: {gpt2_sim:.4f}\")\n",
    "    print(f\"BERT Similarity: {bert_sim:.4f}\")"
   ],
   "id": "199117df36eb1883",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing recipes: 100%|██████████| 2312/2312 [00:00<00:00, 2483.79it/s]\n",
      "Calculating scores: 100%|██████████| 5/5 [00:01<00:00,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recipe 1 (Ingredient Similarity: 0.26):\n",
      "[BOS]ground beef, fresh mushrooms, celery, \u001B[91mtomato\u001B[0m paste, \u001B[91mtomato\u001B[0m sauce, rigatoni \u001B[91mpasta\u001B[0m, cheddar cheese, cream of mushroom soup[STEPS]brown ground beef , drain well, add \u001B[91mtomato\u001B[0m paste , \u001B[91mtomato\u001B[0m sauce and favorite seasonings, layer half of rigatoni noodles on bottom of baking dish, top with half of meat sauce, repeat layers, top with cheese and mushroom soup, bake 1 1 / 2 hours at 300[EOS]\n",
      "ROUGE-L F1: 0.1124\n",
      "GPT-2 Similarity: 0.9995\n",
      "BERT Similarity: 0.9414\n",
      "\n",
      "Recipe 2 (Ingredient Similarity: 0.22):\n",
      "[BOS]cream, tasty cheese, onion, garlic clove, nam pla, \u001B[91mtomato\u001B[0m paste, \u001B[91mfish\u001B[0m fillet[STEPS]make sauce by combining all ingredients in saucepan over medium heat until cheese is melted, place \u001B[91mfish\u001B[0m fillets into baking dish, spoon the sauce onto the fillets, bake at 425 - 450 degrees for 10-15 minutes , or under the griller until cooked and top is browned, \u001B[91mfish\u001B[0m should flake easily with a fork, \"on the other hand , it shouldnt look dried out either\", alternatively , you can also reduce the sauce in a frypan on a medium to hot heat on top of the stove, turn heat down to medium and then cook the fillets in the sauce[EOS]\n",
      "ROUGE-L F1: 0.1613\n",
      "GPT-2 Similarity: 0.9997\n",
      "BERT Similarity: 0.9446\n",
      "\n",
      "Recipe 3 (Ingredient Similarity: 0.17):\n",
      "[BOS]biscuits, \u001B[91mtomato\u001B[0m ketchup, butter[STEPS]butter 1 side of the first cracker and set aside, spread 1 teaspoon of ketchup on the other cracker, place the buttered cracker on top of the one with ketchup , like a sandwich and lightly press together to stick, eat and enjoy ![EOS]\n",
      "ROUGE-L F1: 0.1039\n",
      "GPT-2 Similarity: 0.9993\n",
      "BERT Similarity: 0.8818\n",
      "\n",
      "Recipe 4 (Ingredient Similarity: 0.17):\n",
      "[BOS]olive oil, garlic cloves, boneless skinless chicken breast, water, \u001B[91mtomato\u001B[0m paste, soy sauce, lemon juice, fresh parsley, \u001B[91mpasta\u001B[0m shells[STEPS]heat the oil in a large skillet, add garlic to oil, add the chicken pieces , and stir over medium heat to coat the chicken with the oil and garlic, stir in the water , \u001B[91mtomato\u001B[0m paste , soy sauce , and lemon juice, simmer , covered over low heat for about 5 minutes , stirring once or twice , until the chicken is cooked through, add the parsley and hot shells, toss to coat[EOS]\n",
      "ROUGE-L F1: 0.1584\n",
      "GPT-2 Similarity: 0.9993\n",
      "BERT Similarity: 0.9324\n",
      "\n",
      "Recipe 5 (Ingredient Similarity: 0.16):\n",
      "[BOS]mixed \u001B[91mfish\u001B[0m, squid, onions, garlic, \u001B[91mtomato\u001B[0mes, potatoes, turmeric, \u001B[91mfish\u001B[0m stock, olive oil, egg yolks, cream[STEPS]clean \u001B[91mfish\u001B[0m and squid and cut into serving pieces, arrange onion , garlic , \u001B[91mtomato\u001B[0mes and potatoes in a large saucepan, top with \u001B[91mfish\u001B[0m and enough stock to cover, sprinkle turmeric over, add oil and season to taste, bring to boil , then simmer for 15 minutes, remove \u001B[91mfish\u001B[0m and vegetables to a deep serving dish, beat egg yolks and cream and slowly add hot soup in a thin stream , whisking constantly, return to saucepan and heat through , stirring occasionally, pour over \u001B[91mfish\u001B[0m and serve with garlic bread[EOS]\n",
      "ROUGE-L F1: 0.1552\n",
      "GPT-2 Similarity: 0.9995\n",
      "BERT Similarity: 0.9300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
