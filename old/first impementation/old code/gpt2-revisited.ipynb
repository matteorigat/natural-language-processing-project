{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 8747282,
     "sourceType": "datasetVersion",
     "datasetId": 5252989
    }
   ],
   "dockerImageVersionId": 30732,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-21T14:15:03.117214Z",
     "iopub.execute_input": "2024-06-21T14:15:03.118180Z",
     "iopub.status.idle": "2024-06-21T14:15:03.127763Z",
     "shell.execute_reply.started": "2024-06-21T14:15:03.118142Z",
     "shell.execute_reply": "2024-06-21T14:15:03.126527Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T09:56:08.287922Z",
     "start_time": "2024-06-25T09:56:08.283530Z"
    }
   },
   "outputs": [],
   "execution_count": 121
  },
  {
   "cell_type": "code",
   "source": [
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 4\n",
    "EPOCHS = 3\n",
    "LEARNING_RATE = 1e-05"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-21T14:09:51.032365Z",
     "iopub.execute_input": "2024-06-21T14:09:51.032965Z",
     "iopub.status.idle": "2024-06-21T14:09:51.038399Z",
     "shell.execute_reply.started": "2024-06-21T14:09:51.032931Z",
     "shell.execute_reply": "2024-06-21T14:09:51.037110Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T09:56:08.314732Z",
     "start_time": "2024-06-25T09:56:08.311648Z"
    }
   },
   "outputs": [],
   "execution_count": 122
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"dataset/RAW_recipes.csv\")\n",
    "\n",
    "# Sample a fraction of the dataset\n",
    "sample_size = int(len(df) * 0.001)\n",
    "new_df = df.sample(n=sample_size).reset_index(drop=True)\n",
    "\n",
    "# Preprocess ingredients and steps\n",
    "separator = \", \"\n",
    "new_df['ingredients'] = new_df['ingredients'].apply(lambda x: separator.join(eval(x)))\n",
    "new_df['steps'] = new_df['steps'].apply(lambda x: separator.join(eval(x)))\n",
    "\n",
    "print(new_df.shape)\n",
    "#print(new_df.head())\n",
    "\n",
    "print(\"\\nName:\", new_df.iloc[0]['name'])\n",
    "print(\"\\nIngredients:\", new_df.iloc[0]['ingredients'])\n",
    "print(\"\\nSteps:\", new_df.iloc[0]['steps'])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-21T14:09:51.039644Z",
     "iopub.execute_input": "2024-06-21T14:09:51.039974Z",
     "iopub.status.idle": "2024-06-21T14:09:57.178991Z",
     "shell.execute_reply.started": "2024-06-21T14:09:51.039947Z",
     "shell.execute_reply": "2024-06-21T14:09:57.177664Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T09:56:11.231051Z",
     "start_time": "2024-06-25T09:56:08.348105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(231, 6)\n",
      "Name: lamb stew\n",
      "\n",
      "Ingredients: lamb, sugar, oil, salt, pepper, flour, water, red wine, garlic powder, worcestershire sauce, carrots, onions, celery ribs, potatoes\n",
      "\n",
      "Steps: sprinkle lamb with sugar, brown in oil in skillet, remove lamb and place in slow cooker , reserving drippings, stir in salt , pepper , and flour into drippings until smooth, stir in water and wine , until smooth , stirring until broth simmers and thickens, pour into cooker, add remaining ingredients and stir until well mixed, cover, cook on low 8-10 hours, serve with crusty bread\n"
     ]
    }
   ],
   "execution_count": 123
  },
  {
   "cell_type": "code",
   "source": [
    "train_size = 0.8\n",
    "train_dataset = new_df.sample(frac=train_size, random_state=200).reset_index(drop=True)\n",
    "test_dataset = new_df.drop(train_dataset.index).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nFULL Dataset: {}\".format(new_df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-21T14:09:57.180219Z",
     "iopub.execute_input": "2024-06-21T14:09:57.180544Z",
     "iopub.status.idle": "2024-06-21T14:09:57.195254Z",
     "shell.execute_reply.started": "2024-06-21T14:09:57.180515Z",
     "shell.execute_reply": "2024-06-21T14:09:57.193973Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T09:56:11.235829Z",
     "start_time": "2024-06-25T09:56:11.231941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FULL Dataset: (231, 6)\n",
      "TRAIN Dataset: (185, 6)\n",
      "TEST Dataset: (46, 6)\n"
     ]
    }
   ],
   "execution_count": 124
  },
  {
   "cell_type": "code",
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.name = dataframe.name\n",
    "        self.ingredients = dataframe.ingredients\n",
    "        self.steps = dataframe.steps\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #ingredients = str(self.ingredients[index])\n",
    "        #steps = str(self.steps[index])\n",
    "        \n",
    "        recipe = '[BOS]'+self.ingredients[index]+'[STEPS]'+self.steps[index]+'[EOS]' \n",
    "        #+self.name[index]+'[INGREDIENTS]'+\n",
    "        \n",
    "        # Tokenize ingredients\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            recipe,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(inputs[\"token_type_ids\"], dtype=torch.long),\n",
    "        }"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-21T14:09:57.198508Z",
     "iopub.execute_input": "2024-06-21T14:09:57.199147Z",
     "iopub.status.idle": "2024-06-21T14:09:57.211058Z",
     "shell.execute_reply.started": "2024-06-21T14:09:57.199112Z",
     "shell.execute_reply": "2024-06-21T14:09:57.209919Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T09:56:11.240209Z",
     "start_time": "2024-06-25T09:56:11.236736Z"
    }
   },
   "outputs": [],
   "execution_count": 125
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the GPT tokenizer.\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\", bos_token='[BOS]', eos_token='[EOS]', pad_token='[PAD]')\n",
    "\n",
    "# add special tokens for title, ingredients and instruction seperator\n",
    "special_tokens_dict = {'additional_special_tokens': ['[STEPS]']}  #'[INGREDIENTS]', \n",
    "\n",
    "# check the number of special tokens\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "print('We have added', num_added_toks, 'tokens')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-21T14:15:10.174795Z",
     "iopub.execute_input": "2024-06-21T14:15:10.175308Z",
     "iopub.status.idle": "2024-06-21T14:15:51.657215Z",
     "shell.execute_reply.started": "2024-06-21T14:15:10.175268Z",
     "shell.execute_reply": "2024-06-21T14:15:51.655372Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T09:56:11.747995Z",
     "start_time": "2024-06-25T09:56:11.241429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 1 tokens\n"
     ]
    }
   ],
   "execution_count": 126
  },
  {
   "cell_type": "code",
   "source": "# Create instances of CustomDataset\ntrain_dataset = CustomDataset(train_dataset, tokenizer, MAX_LEN)\ntest_dataset = CustomDataset(test_dataset, tokenizer, MAX_LEN)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-21T14:12:18.082515Z",
     "iopub.status.idle": "2024-06-21T14:12:18.082897Z",
     "shell.execute_reply.started": "2024-06-21T14:12:18.082723Z",
     "shell.execute_reply": "2024-06-21T14:12:18.082738Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T09:56:11.751401Z",
     "start_time": "2024-06-25T09:56:11.748759Z"
    }
   },
   "outputs": [],
   "execution_count": 127
  },
  {
   "cell_type": "code",
   "source": "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': 0}\n\ntest_params = {'batch_size': VALID_BATCH_SIZE,\n               'shuffle': True,\n               'num_workers': 0}\n\ntraining_loader = DataLoader(train_dataset, **train_params)\ntesting_loader = DataLoader(test_dataset, **test_params)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-21T14:12:18.084185Z",
     "iopub.status.idle": "2024-06-21T14:12:18.084538Z",
     "shell.execute_reply.started": "2024-06-21T14:12:18.084372Z",
     "shell.execute_reply": "2024-06-21T14:12:18.084387Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T09:56:11.759212Z",
     "start_time": "2024-06-25T09:56:11.752420Z"
    }
   },
   "outputs": [],
   "execution_count": 128
  },
  {
   "cell_type": "code",
   "source": [
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#if torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#    x = torch.ones(1, device=device)\n",
    "#    print(x)\n",
    "#else:\n",
    "#    print(\"MPS device not found.\")\n",
    "print(f\"Using {device} device\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-21T14:12:18.086265Z",
     "iopub.status.idle": "2024-06-21T14:12:18.086667Z",
     "shell.execute_reply.started": "2024-06-21T14:12:18.086461Z",
     "shell.execute_reply": "2024-06-21T14:12:18.086477Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T09:56:11.762124Z",
     "start_time": "2024-06-25T09:56:11.759993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "execution_count": 129
  },
  {
   "cell_type": "code",
   "source": [
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-21T14:12:18.088192Z",
     "iopub.status.idle": "2024-06-21T14:12:18.088541Z",
     "shell.execute_reply.started": "2024-06-21T14:12:18.088376Z",
     "shell.execute_reply": "2024-06-21T14:12:18.088391Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T09:56:14.055648Z",
     "start_time": "2024-06-25T09:56:11.762630Z"
    }
   },
   "outputs": [],
   "execution_count": 130
  },
  {
   "cell_type": "code",
   "source": "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-21T14:12:18.090029Z",
     "iopub.status.idle": "2024-06-21T14:12:18.090522Z",
     "shell.execute_reply.started": "2024-06-21T14:12:18.090269Z",
     "shell.execute_reply": "2024-06-21T14:12:18.090291Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T09:56:14.107154Z",
     "start_time": "2024-06-25T09:56:14.056614Z"
    }
   },
   "outputs": [],
   "execution_count": 131
  },
  {
   "cell_type": "code",
   "source": [
    "def train_loop(dataloader, model, optimizer):\n",
    "    \n",
    "    # set the model to training model\n",
    "    model.train()\n",
    "    \n",
    "    loop = tqdm(dataloader, leave=True)\n",
    "    for batch in loop:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        token_type_ids = batch['token_type_ids'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "\n",
    "def test_loop(dataloader, model):\n",
    "    # set the model of evaluation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    \n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # previous tokens\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            \n",
    "           # get outputs from model\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, labels=input_ids)\n",
    "\n",
    "            # calculate loss\n",
    "            val_loss += outputs.loss.item()\n",
    "    \n",
    "    # Print the validation loss for this epoch\n",
    "    print(f\"Validation Loss: {val_loss / len(dataloader)}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-21T14:12:18.092941Z",
     "iopub.status.idle": "2024-06-21T14:12:18.093284Z",
     "shell.execute_reply.started": "2024-06-21T14:12:18.093118Z",
     "shell.execute_reply": "2024-06-21T14:12:18.093133Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T09:56:14.114418Z",
     "start_time": "2024-06-25T09:56:14.110271Z"
    }
   },
   "outputs": [],
   "execution_count": 132
  },
  {
   "cell_type": "code",
   "source": "# Training and validation\nfor epoch in range(EPOCHS):\n    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n    train_loop(training_loader, model, optimizer)\n    test_loop(testing_loader, model)\n\nprint(\"Training completed!\")",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-21T14:12:18.094144Z",
     "iopub.status.idle": "2024-06-21T14:12:18.094501Z",
     "shell.execute_reply.started": "2024-06-21T14:12:18.094322Z",
     "shell.execute_reply": "2024-06-21T14:12:18.094338Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T10:12:02.353210Z",
     "start_time": "2024-06-25T09:56:14.115638Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [05:03<00:00, 12.65s/it, loss=2.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.5405129194259644\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [04:55<00:00, 12.33s/it, loss=2.2] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.794088453054428\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [04:57<00:00, 12.42s/it, loss=2.62]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 2.576580067475637\n",
      "Training completed!\n"
     ]
    }
   ],
   "execution_count": 133
  },
  {
   "cell_type": "code",
   "source": [
    "model.save_pretrained(\"fine_tuned_model\")\n",
    "tokenizer.save_pretrained(\"fine_tuned_model\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-21T14:12:18.095610Z",
     "iopub.status.idle": "2024-06-21T14:12:18.095934Z",
     "shell.execute_reply.started": "2024-06-21T14:12:18.095773Z",
     "shell.execute_reply": "2024-06-21T14:12:18.095787Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T10:12:02.981366Z",
     "start_time": "2024-06-25T10:12:02.362405Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fine_tuned_model/tokenizer_config.json',\n",
       " 'fine_tuned_model/special_tokens_map.json',\n",
       " 'fine_tuned_model/vocab.json',\n",
       " 'fine_tuned_model/merges.txt',\n",
       " 'fine_tuned_model/added_tokens.json')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 134
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the fine-tuned GPT-2 model and tokenizer\n",
    "#model_name = \"fine_tuned_model\"\n",
    "#model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
    "#tokenizer = GPT2Tokenizer.from_pretrained(model_name)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-06-21T14:12:18.097604Z",
     "iopub.status.idle": "2024-06-21T14:12:18.097972Z",
     "shell.execute_reply.started": "2024-06-21T14:12:18.097799Z",
     "shell.execute_reply": "2024-06-21T14:12:18.097815Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T10:12:02.986164Z",
     "start_time": "2024-06-25T10:12:02.983650Z"
    }
   },
   "outputs": [],
   "execution_count": 135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T10:16:33.900299Z",
     "start_time": "2024-06-25T10:16:33.893003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_recipe(ingredients, model, tokenizer, max_length=400, temperature=0.1, top_k=100, top_p=0.2):\n",
    "    input_text = ingredients\n",
    "    input_ids = tokenizer(input_text, return_tensors='pt').input_ids.to(device)\n",
    "    \n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        temperature=temperature, # Lower values make the model more confident (less random), while higher values increase randomness.\n",
    "        top_k=top_k,  #Increase to consider more tokens, decrease to restrict the model’s choices.\n",
    "        top_p=top_p,  # Increase to allow more diversity, decrease to make the model more conservative.\n",
    "        num_beams=20,\n",
    "        no_repeat_ngram_size=2,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True\n",
    "    )\n",
    "    \n",
    "    recipe = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "    return recipe"
   ],
   "outputs": [],
   "execution_count": 139
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the question\n",
    "ingredients = \"flour, sugar, cinnamon, carrot, apple, walnuts\"\n",
    "\n",
    "ingredients = '[INGREDIENTS]'+ ingredients + '[STEPS]'\n",
    "generated_recipe = generate_recipe(ingredients, model, tokenizer)\n",
    "\n",
    "print(generated_recipe)\n",
    "print(\"\\n\", len(generated_recipe) - len(ingredients))"
   ],
   "metadata": {
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-06-25T10:16:37.326680Z",
     "start_time": "2024-06-25T10:16:36.083721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INGREDIENTS]flour, sugar, cinnamon, carrot, apple, walnuts [STEPS] [PAD][PAD][EOS]\n",
      "\n",
      " 17\n"
     ]
    }
   ],
   "execution_count": 140
  }
 ]
}
