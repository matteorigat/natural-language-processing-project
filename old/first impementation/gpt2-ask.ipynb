{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-10T14:30:19.044357Z",
     "start_time": "2024-09-10T14:30:14.697852Z"
    }
   },
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from rouge import Rouge\n",
    "import torch\n",
    "import csv\n",
    "import random\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import BertModel, BertTokenizer\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T14:30:19.047105Z",
     "start_time": "2024-09-10T14:30:19.045409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "saved_model = \"Models/colab_model_2\"\n",
    "model_name = \"gpt2\""
   ],
   "id": "9ad32890326697be",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T14:30:19.340692Z",
     "start_time": "2024-09-10T14:30:19.047756Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the GPT tokenizer.\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name, bos_token='[BOS]', eos_token='[EOS]', pad_token='[PAD]')\n",
    "# add special tokens for title, ingredients and instruction seperator\n",
    "special_tokens_dict = {'additional_special_tokens': ['[STEPS]']} #'[INGREDIENTS]', \n",
    "# check the number of special tokens\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "print('We have added', num_added_toks, 'tokens')"
   ],
   "id": "ca1255941f36fbb1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 1 tokens\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T14:30:19.894942Z",
     "start_time": "2024-09-10T14:30:19.341390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the trained GPT-2 model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained(saved_model)\n",
    "\n",
    "# Ensure the model is on the right device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ],
   "id": "165285e2cfc6ebef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50261, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50261, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T14:30:19.899779Z",
     "start_time": "2024-09-10T14:30:19.897077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_recipe(ingredients, model, tokenizer, max_length=300, temperature=0.1, top_k=50, top_p=0.1):\n",
    "    input_text = '[BOS]' + ingredients + '[STEPS]'\n",
    "    input_ids = tokenizer(input_text, return_tensors='pt').input_ids.to(device)\n",
    "    \n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_length,\n",
    "        temperature=temperature, # Lower values make the model more confident (less random), while higher values increase randomness.\n",
    "        top_k=top_k,  #Increase to consider more tokens, decrease to restrict the modelâ€™s choices.\n",
    "        top_p=top_p,  # Increase to allow more diversity, decrease to make the model more conservative.\n",
    "        num_beams=5,\n",
    "        no_repeat_ngram_size=2,\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        do_sample=True\n",
    "    )\n",
    "    \n",
    "    recipe = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "    \n",
    "    # Replace lowercase special tokens with uppercase\n",
    "    recipe = recipe.replace('[bos]', '[BOS]').replace('[steps]', '[STEPS]').replace('[eos]', '[EOS]')\n",
    "    \n",
    "    recipe = recipe.split('[EOS]', 1)[0] + '[EOS]'\n",
    "        \n",
    "    return recipe"
   ],
   "id": "3dce51f769144fd4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T14:30:19.903006Z",
     "start_time": "2024-09-10T14:30:19.900826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_highlighted(generated_recipe, ingredients):\n",
    "    recipe=generated_recipe\n",
    "    ingredients_list = [ing.strip().lower() for ing in ingredients.split(',')]\n",
    "    for ingredient in ingredients_list:\n",
    "        recipe = recipe.replace(ingredient, f'\\033[91m{ingredient}\\033[0m')\n",
    "    return recipe"
   ],
   "id": "14db32a328345733",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T14:30:35.066523Z",
     "start_time": "2024-09-10T14:30:19.904009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "ingredients = \"tomatoes, mozzarella, pasta, salad\"\n",
    "\n",
    "generated_recipe = generate_recipe(ingredients, model, tokenizer)\n",
    "    \n",
    "print(print_highlighted(generated_recipe, ingredients))\n",
    "print(\"\\n\", len(generated_recipe) - len(ingredients))"
   ],
   "id": "2e215ecde86eeb55",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BOS]\u001B[91mtomatoes\u001B[0m, \u001B[91mmozzarella\u001B[0m, \u001B[91mpasta\u001B[0m, \u001B[91msalad\u001B[0m [STEPS]  seasoning, boneless skinless chicken breast, cheese, oil, clove, tomato[STEPS]preheat oven to 350 degrees, heat oil in a large skillet over medium-high heat, season chicken with salt and pepper, add chicken and cook until browned on both sides, about 4 minutes per side, remove chicken from skillet and set aside, in same skillet, saute onion and garlic in oil until tender, stir in \u001B[91mtomatoes\u001B[0m, undrained \u001B[91mtomatoes\u001B[0m and italian seasoning and bring to a boil, reduce heat to low and simmer, uncovered, for 10 minutes, meanwhile, cook \u001B[91mpasta\u001B[0m according to package directions, drain \u001B[91mpasta\u001B[0m and add to sauce, toss to coat, place \u001B[91mpasta\u001B[0m on a serving platter and spoon sauce over chicken, sprinkle with parmesan cheese and serve[EOS]\n",
      "\n",
      " 734\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate the generated recipe",
   "id": "2e1f60401ab845db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T14:30:35.070705Z",
     "start_time": "2024-09-10T14:30:35.067525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load and also preprocess the raw data\n",
    "def load_preprocess_raw_data(raw_data):\n",
    "    recipe_instances = []\n",
    "\n",
    "    with open(raw_data, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            # Extract relevant fields from CSV row\n",
    "            #name = row['name'].lower().replace('\"', '')  # Remove any extra quotes\n",
    "            ingredients = row['ingredients'].lower().replace('\\'', '').replace('[', '').replace(']', '')\n",
    "            instructions = row['steps'].lower().replace('\\'', '').replace('[', '').replace(']', '')\n",
    "\n",
    "            # Prepare recipe instance string\n",
    "            recipe_instance = '[BOS]' + ingredients + '[STEPS]' + instructions + '[EOS]'  #+name+'[INGREDIENTS]'\n",
    "\n",
    "            # Limit length to 2000 characters as per your function\n",
    "            if len(recipe_instance) <= 3000:\n",
    "                recipe_instances.append(recipe_instance)\n",
    "\n",
    "    return recipe_instances"
   ],
   "id": "dc8f49e07f4f214d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T14:30:36.383290Z",
     "start_time": "2024-09-10T14:30:35.072083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create text list for dataset\n",
    "# https://www.kaggle.com/datasets/shuyangli94/food-com-recipes-and-user-interactions/data\n",
    "recipe_list = load_preprocess_raw_data(\"dataset/RAW_merged.csv\")\n",
    "recipe_list = random.sample(recipe_list, int(0.01 * len(recipe_list)))"
   ],
   "id": "fa0dfde3c3812d48",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T14:30:37.406611Z",
     "start_time": "2024-09-10T14:30:36.383886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize models and tokenizers\n",
    "model_name_bert = 'bert-base-uncased'\n",
    "tokenizer_bert = BertTokenizer.from_pretrained(model_name_bert)\n",
    "model_bert = BertModel.from_pretrained(model_name_bert)\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "\n",
    "# Function to calculate ROUGE-L F1 score\n",
    "def calculate_rouge_score(text1, text2):\n",
    "    scores = rouge.get_scores(text1, text2)\n",
    "    rouge_l_f1 = scores[0]['rouge-l']['f']\n",
    "    return rouge_l_f1\n",
    "\n",
    "\n",
    "# Function to get GPT-2 embeddings\n",
    "def get_gpt2_embedding(text, model, tokenizer):\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    hidden_states = outputs[0]\n",
    "    pooled_embedding = torch.mean(hidden_states, dim=1)\n",
    "    return pooled_embedding\n",
    "\n",
    "\n",
    "# Function to calculate cosine similarity for GPT-2 embeddings\n",
    "def calculate_gpt2_similarity(text1, text2, model, tokenizer):\n",
    "    embedding1 = get_gpt2_embedding(text1, model, tokenizer)\n",
    "    embedding2 = get_gpt2_embedding(text2, model, tokenizer)\n",
    "    similarity = cosine_similarity(embedding1, embedding2).item()\n",
    "    return similarity\n",
    "\n",
    "\n",
    "# Function to encode text for BERT\n",
    "def encode_text(text, tokenizer):\n",
    "    input_ids = tokenizer.encode(text, return_tensors='pt', max_length=512, truncation=True)\n",
    "    return input_ids\n",
    "\n",
    "\n",
    "# Function to calculate BERT embeddings\n",
    "def get_bert_embedding(input_ids, model):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        pooled_embedding = torch.mean(last_hidden_state, dim=1)\n",
    "    return pooled_embedding\n",
    "\n",
    "\n",
    "# Function to calculate cosine similarity for BERT embeddings\n",
    "def calculate_bert_similarity(text1, text2, model, tokenizer):\n",
    "    input1 = encode_text(text1, tokenizer)\n",
    "    input2 = encode_text(text2, tokenizer)\n",
    "    embedding1 = get_bert_embedding(input1, model)\n",
    "    embedding2 = get_bert_embedding(input2, model)\n",
    "    similarity = cosine_similarity(embedding1.cpu(), embedding2.cpu()).item()\n",
    "    return similarity\n",
    "\n",
    "\n",
    "# Function to evaluate generated recipe against a list of real recipes\n",
    "def evaluate_generated_recipe(generated_recipe, real_recipes):\n",
    "    rouge_scores = []\n",
    "    gpt2_similarities = []\n",
    "    bert_similarities = []\n",
    "\n",
    "    for real_recipe in tqdm(real_recipes, desc=\"Evaluating recipes\"):\n",
    "        rouge_score = calculate_rouge_score(generated_recipe, real_recipe)\n",
    "        gpt2_similarity = calculate_gpt2_similarity(generated_recipe, real_recipe, model, tokenizer)\n",
    "        bert_similarity = calculate_bert_similarity(generated_recipe, real_recipe, model_bert, tokenizer_bert)\n",
    "\n",
    "        rouge_scores.append(rouge_score)\n",
    "        gpt2_similarities.append(gpt2_similarity)\n",
    "        bert_similarities.append(bert_similarity)\n",
    "\n",
    "    # Calculate average scores\n",
    "    avg_scores = [(sum(scores) / len(scores)) for scores in zip(rouge_scores)]\n",
    "    #, gpt2_similarities, bert_similarities\n",
    "\n",
    "    # Find index of recipe with maximum average score\n",
    "    max_index = avg_scores.index(max(avg_scores))\n",
    "\n",
    "    return real_recipes[max_index], rouge_scores[max_index], gpt2_similarities[max_index], bert_similarities[max_index]"
   ],
   "id": "f6c97dbc2dd3d3c5",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T14:31:31.596244Z",
     "start_time": "2024-09-10T14:30:37.407507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_recipe = evaluate_generated_recipe(generated_recipe, recipe_list)\n",
    "\n",
    "print(\"Generated Recipe:\")\n",
    "print(print_highlighted(generated_recipe, ingredients))\n",
    "print(\"\\nMost Similar Real Recipe:\")\n",
    "print(print_highlighted(best_recipe[0], ingredients), \"\\n\\nrouge-l f1:\", best_recipe[1], \"\\nGPT-2 similarity:\",\n",
    "      best_recipe[2], \"\\nBERT similarity:\", best_recipe[3])"
   ],
   "id": "ce011dff65770dc4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating recipes:   6%|â–Œ         | 101/1782 [00:53<14:54,  1.88it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m best_recipe \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_generated_recipe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgenerated_recipe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrecipe_list\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGenerated Recipe:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(print_highlighted(generated_recipe, ingredients))\n",
      "Cell \u001B[0;32mIn[10], line 68\u001B[0m, in \u001B[0;36mevaluate_generated_recipe\u001B[0;34m(generated_recipe, real_recipes)\u001B[0m\n\u001B[1;32m     66\u001B[0m rouge_score \u001B[38;5;241m=\u001B[39m calculate_rouge_score(generated_recipe, real_recipe)\n\u001B[1;32m     67\u001B[0m gpt2_similarity \u001B[38;5;241m=\u001B[39m calculate_gpt2_similarity(generated_recipe, real_recipe, model, tokenizer)\n\u001B[0;32m---> 68\u001B[0m bert_similarity \u001B[38;5;241m=\u001B[39m \u001B[43mcalculate_bert_similarity\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgenerated_recipe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreal_recipe\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_bert\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer_bert\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     70\u001B[0m rouge_scores\u001B[38;5;241m.\u001B[39mappend(rouge_score)\n\u001B[1;32m     71\u001B[0m gpt2_similarities\u001B[38;5;241m.\u001B[39mappend(gpt2_similarity)\n",
      "Cell \u001B[0;32mIn[10], line 53\u001B[0m, in \u001B[0;36mcalculate_bert_similarity\u001B[0;34m(text1, text2, model, tokenizer)\u001B[0m\n\u001B[1;32m     51\u001B[0m input1 \u001B[38;5;241m=\u001B[39m encode_text(text1, tokenizer)\n\u001B[1;32m     52\u001B[0m input2 \u001B[38;5;241m=\u001B[39m encode_text(text2, tokenizer)\n\u001B[0;32m---> 53\u001B[0m embedding1 \u001B[38;5;241m=\u001B[39m \u001B[43mget_bert_embedding\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput1\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m embedding2 \u001B[38;5;241m=\u001B[39m get_bert_embedding(input2, model)\n\u001B[1;32m     55\u001B[0m similarity \u001B[38;5;241m=\u001B[39m cosine_similarity(embedding1\u001B[38;5;241m.\u001B[39mcpu(), embedding2\u001B[38;5;241m.\u001B[39mcpu())\u001B[38;5;241m.\u001B[39mitem()\n",
      "Cell \u001B[0;32mIn[10], line 43\u001B[0m, in \u001B[0;36mget_bert_embedding\u001B[0;34m(input_ids, model)\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_bert_embedding\u001B[39m(input_ids, model):\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[0;32m---> 43\u001B[0m         outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     44\u001B[0m         last_hidden_state \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mlast_hidden_state\n\u001B[1;32m     45\u001B[0m         pooled_embedding \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmean(last_hidden_state, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-project/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1137\u001B[0m, in \u001B[0;36mBertModel.forward\u001B[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m   1130\u001B[0m \u001B[38;5;66;03m# Prepare head mask if needed\u001B[39;00m\n\u001B[1;32m   1131\u001B[0m \u001B[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m \u001B[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001B[39;00m\n\u001B[1;32m   1133\u001B[0m \u001B[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001B[39;00m\n\u001B[1;32m   1134\u001B[0m \u001B[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001B[39;00m\n\u001B[1;32m   1135\u001B[0m head_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_head_mask(head_mask, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconfig\u001B[38;5;241m.\u001B[39mnum_hidden_layers)\n\u001B[0;32m-> 1137\u001B[0m encoder_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1138\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1139\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1141\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1142\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoder_extended_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1143\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpast_key_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpast_key_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1144\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_cache\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_cache\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1145\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1146\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1147\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1148\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1149\u001B[0m sequence_output \u001B[38;5;241m=\u001B[39m encoder_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m   1150\u001B[0m pooled_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler(sequence_output) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpooler \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-project/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:690\u001B[0m, in \u001B[0;36mBertEncoder.forward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001B[0m\n\u001B[1;32m    679\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gradient_checkpointing_func(\n\u001B[1;32m    680\u001B[0m         layer_module\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m,\n\u001B[1;32m    681\u001B[0m         hidden_states,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    687\u001B[0m         output_attentions,\n\u001B[1;32m    688\u001B[0m     )\n\u001B[1;32m    689\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 690\u001B[0m     layer_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    691\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    692\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    693\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    694\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    695\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    696\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    697\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    698\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    700\u001B[0m hidden_states \u001B[38;5;241m=\u001B[39m layer_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    701\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_cache:\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-project/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:580\u001B[0m, in \u001B[0;36mBertLayer.forward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[1;32m    568\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[1;32m    569\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    570\u001B[0m     hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    577\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[1;32m    578\u001B[0m     \u001B[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001B[39;00m\n\u001B[1;32m    579\u001B[0m     self_attn_past_key_value \u001B[38;5;241m=\u001B[39m past_key_value[:\u001B[38;5;241m2\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m past_key_value \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 580\u001B[0m     self_attention_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattention\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    581\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    582\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    583\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    584\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    585\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mself_attn_past_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    586\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    587\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m self_attention_outputs[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    589\u001B[0m     \u001B[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-project/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:510\u001B[0m, in \u001B[0;36mBertAttention.forward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[1;32m    500\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[1;32m    501\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    502\u001B[0m     hidden_states: torch\u001B[38;5;241m.\u001B[39mTensor,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    508\u001B[0m     output_attentions: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    509\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[torch\u001B[38;5;241m.\u001B[39mTensor]:\n\u001B[0;32m--> 510\u001B[0m     self_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mself\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    511\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    512\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    513\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    514\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    515\u001B[0m \u001B[43m        \u001B[49m\u001B[43mencoder_attention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    516\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpast_key_value\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    517\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    518\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    519\u001B[0m     attention_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutput(self_outputs[\u001B[38;5;241m0\u001B[39m], hidden_states)\n\u001B[1;32m    520\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m (attention_output,) \u001B[38;5;241m+\u001B[39m self_outputs[\u001B[38;5;241m1\u001B[39m:]  \u001B[38;5;66;03m# add attentions if we output them\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-project/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/nlp-project/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:435\u001B[0m, in \u001B[0;36mBertSdpaSelfAttention.forward\u001B[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001B[0m\n\u001B[1;32m    431\u001B[0m \u001B[38;5;66;03m# The tgt_len > 1 is necessary to match with AttentionMaskConverter.to_causal_4d that does not create a causal\u001B[39;00m\n\u001B[1;32m    432\u001B[0m \u001B[38;5;66;03m# mask in case tgt_len == 1.\u001B[39;00m\n\u001B[1;32m    433\u001B[0m is_causal \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_decoder \u001B[38;5;129;01mand\u001B[39;00m attention_mask \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m tgt_len \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 435\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunctional\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscaled_dot_product_attention\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    436\u001B[0m \u001B[43m    \u001B[49m\u001B[43mquery_layer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    437\u001B[0m \u001B[43m    \u001B[49m\u001B[43mkey_layer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    438\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalue_layer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    439\u001B[0m \u001B[43m    \u001B[49m\u001B[43mattn_mask\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattention_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    440\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdropout_p\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout_prob\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    441\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_causal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_causal\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    442\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    444\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m attn_output\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m    445\u001B[0m attn_output \u001B[38;5;241m=\u001B[39m attn_output\u001B[38;5;241m.\u001B[39mreshape(bsz, tgt_len, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mall_head_size)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# Function to extract ingredients from a recipe\n",
    "def extract_ingredients(recipe):\n",
    "    start = recipe.find('[BOS]') + len('[BOS]')\n",
    "    end = recipe.find('[STEPS]')\n",
    "    ingredients = recipe[start:end].strip()\n",
    "    return ingredients\n",
    "\n",
    "\n",
    "# Function to calculate cosine similarity for ingredient lists\n",
    "def calculate_ingredient_similarity(ingredients1, ingredients2):\n",
    "    vectorizer = TfidfVectorizer().fit_transform([ingredients1, ingredients2])\n",
    "    vectors = vectorizer.toarray()\n",
    "    cosine_sim = cosine_similarity(vectors)\n",
    "    return cosine_sim[0, 1]\n",
    "\n",
    "\n",
    "# Function to evaluate generated recipe against a list of real recipes\n",
    "def evaluate_generated_recipe_by_ingredients(generated_recipe, real_recipes, top_k=5):\n",
    "    generated_ingredients = extract_ingredients(generated_recipe)\n",
    "\n",
    "    similarities = []\n",
    "    for real_recipe in tqdm(real_recipes, desc=\"Processing recipes\"):\n",
    "        real_ingredients = extract_ingredients(real_recipe)\n",
    "        similarity = calculate_ingredient_similarity(generated_ingredients, real_ingredients)\n",
    "        similarities.append((real_recipe, similarity))\n",
    "\n",
    "    # Sort recipes based on ingredient similarity\n",
    "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get top k recipes\n",
    "    top_k_recipes = similarities[:top_k]\n",
    "\n",
    "    results = []\n",
    "    for real_recipe, sim in tqdm(top_k_recipes, desc=\"Calculating scores\"):\n",
    "        rouge_score = calculate_rouge_score(generated_recipe, real_recipe)\n",
    "        gpt2_similarity = calculate_gpt2_similarity(generated_recipe, real_recipe, model, tokenizer)\n",
    "        bert_similarity = calculate_bert_similarity(generated_recipe, real_recipe, model_bert, tokenizer_bert)\n",
    "        results.append((real_recipe, sim, rouge_score, gpt2_similarity, bert_similarity))\n",
    "\n",
    "    return results"
   ],
   "id": "802c02028ffee9c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate and print top k recipes\n",
    "top_k = 5\n",
    "top_k_recipes = evaluate_generated_recipe_by_ingredients(generated_recipe, recipe_list, top_k=top_k)\n",
    "\n",
    "for i, (recipe, ingredient_sim, rouge_score, gpt2_sim, bert_sim) in enumerate(top_k_recipes):\n",
    "    print(f\"\\nRecipe {i + 1} (Ingredient Similarity: {ingredient_sim:.2f}):\")\n",
    "    print(print_highlighted(recipe, ingredients))\n",
    "    print(f\"ROUGE-L F1: {rouge_score:.4f}\")\n",
    "    print(f\"GPT-2 Similarity: {gpt2_sim:.4f}\")\n",
    "    print(f\"BERT Similarity: {bert_sim:.4f}\")"
   ],
   "id": "199117df36eb1883",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
