{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T09:39:04.734794Z",
     "start_time": "2024-10-09T09:39:04.731709Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config\n",
    "from transformers import get_linear_schedule_with_warmup\n"
   ],
   "id": "19ca7bc8df5d6f71",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T09:39:04.754850Z",
     "start_time": "2024-10-09T09:39:04.752540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# some parameters\n",
    "epochs = 5\n",
    "learning_rate = 5e-5 #default 1e-3 5e-5\n",
    "epsilon = 1e-8 #default\n",
    "model_name = \"gpt2\"\n",
    "batch_size = 4\n",
    "\n",
    "# this produces sample output every 100 steps\n",
    "sample_every = 100\n",
    "# save the model every 1000 step\n",
    "save_every = 1000\n",
    "# save the model to this file name\n",
    "save_model = \"models/topsmallest_epochs\""
   ],
   "id": "fce95e3efb4faf30",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T09:43:48.290932Z",
     "start_time": "2024-10-09T09:43:48.279545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer, word_tokenize, pos_tag\n",
    "import re\n",
    "\n",
    "# Ensure NLTK downloads\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_ingredients(ingredients):\n",
    "    ingredients_list = eval(ingredients)\n",
    "    processed_ingredients = []\n",
    "    regex = re.compile('[^a-zA-Z ]')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    #stemmer = PorterStemmer()\n",
    "    \n",
    "    # POS tags that represent nouns\n",
    "    noun_tags = ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "    \n",
    "    # Define the words to be dropped\n",
    "    #words_to_drop = {\"powder\", \"brown\", \"salt\", \"water\", \"sugar\", \"onion\", \"butter\", \"pepper\", \"ground\", \"cream\"} \n",
    "\n",
    "    for ingr in ingredients_list:\n",
    "        ingr = regex.sub(' ', ingr.lower()).strip()\n",
    "        components = [comp.strip() for comp in ingr.split('and')]\n",
    "        \n",
    "\n",
    "        for comp in components:\n",
    "                        \n",
    "            sentence = \"\"\n",
    "            tokens = word_tokenize(comp)  # Tokenize each component\n",
    "            tagged_tokens = pos_tag(tokens)  # Perform POS tagging\n",
    "            \n",
    "            # Extract main nouns while handling compound nouns\n",
    "            nouns = []\n",
    "            current_noun = \"\"\n",
    "            for word, tag in tagged_tokens:\n",
    "                word = lemmatizer.lemmatize(word.strip())\n",
    "                if len(word) > 2 and word not in stop_words and tag in noun_tags: # and word not in words_to_drop\n",
    "                    if current_noun:\n",
    "                        nouns.append(current_noun)\n",
    "                        current_noun = \"\"\n",
    "                    current_noun = word\n",
    "            \n",
    "            # Add last current noun if exists\n",
    "            if current_noun:\n",
    "                nouns.append(current_noun)            \n",
    "            \n",
    "            for word in nouns:\n",
    "                singular_comp = lemmatizer.lemmatize(word.strip())\n",
    "                #stemmed_word = stemmer.stem(singular_comp)\n",
    "            \n",
    "                if singular_comp not in stop_words and len(singular_comp) > 2:\n",
    "                    sentence += singular_comp + \" \"\n",
    "                    \n",
    "            if sentence.strip():\n",
    "                processed_ingredients.append(sentence.strip())\n",
    "\n",
    "    return list(set(processed_ingredients))\n",
    "\n",
    "# Funzione di preprocessing per le tecniche\n",
    "def preprocess_techniques(techniques):\n",
    "    techniques_list = eval(techniques)\n",
    "    processed_techniques = []\n",
    "\n",
    "    for technique in techniques_list:\n",
    "        technique = technique.lower().strip()\n",
    "        tokens = word_tokenize(technique)\n",
    "        tokens = [token for token in tokens if token not in stop_words and len(token) > 2]\n",
    "        processed_techniques.append(' '.join(tokens))\n",
    "\n",
    "    return processed_techniques\n",
    "\n",
    "def normalize_fractions(step):\n",
    "    # Rimuove gli spazi attorno al simbolo della frazione\n",
    "    return re.sub(r'(\\d+)\\s*/\\s*(\\d+)', r'\\1/\\2', step)\n",
    "\n",
    "def preprocess_steps(steps):\n",
    "    steps_list = eval(steps)\n",
    "    processed_steps = []\n",
    "\n",
    "    for step in steps_list:\n",
    "        step = step.lower().strip()\n",
    "        step = normalize_fractions(step)\n",
    "        tokens = word_tokenize(step)\n",
    "        tokens = [re.sub(r\"[^a-zA-Z0-9,./-]+\", \"\", token) for token in tokens]\n",
    "        tokens = [token for token in tokens if token and token != '--']\n",
    "        processed_steps.append(' '.join(tokens))\n",
    "\n",
    "    return processed_steps"
   ],
   "id": "f39a9f740aad3497",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/matteorigat/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/matteorigat/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/matteorigat/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/matteorigat/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/matteorigat/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T09:43:50.590253Z",
     "start_time": "2024-10-09T09:43:50.585550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Funzione per preprocessare ogni riga della ricetta\n",
    "def process_recipe(row):\n",
    "    ingredients = preprocess_ingredients(row['ingredients'])\n",
    "    techniques = preprocess_techniques(row['techniques_list'])\n",
    "    instructions = preprocess_steps(row['steps'])\n",
    "    #instructions = row['steps'].lower().replace('\\'', '').replace('[', '').replace(']', '').replace('\"', '')\n",
    "    \n",
    "    ingredients_str = ', '.join(ingredients)\n",
    "    techniques_str = ', '.join(techniques)\n",
    "    instructions_str = '. '.join(instructions)\n",
    "    instructions_str = instructions_str.replace(\" ,\", \",\")\n",
    "\n",
    "    recipe_instance = f\"[BOS] [INGREDIENTS] {ingredients_str} [TECHNIQUES] {techniques_str} [STEPS] {instructions_str} [EOS]\"\n",
    "    return recipe_instance"
   ],
   "id": "1e29c3209be883b2",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T09:43:52.298804Z",
     "start_time": "2024-10-09T09:43:52.293702Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "# Funzione per preprocessare i dati in parallelo\n",
    "def load_preprocess_raw_data_parallel(raw_data):\n",
    "    with open(raw_data, 'r', encoding='utf-8') as f:\n",
    "        reader = list(csv.DictReader(f))  # Convertiamo reader in una lista\n",
    "        num_cores = multiprocessing.cpu_count()  # Otteniamo il numero di core della CPU\n",
    "        print(f\"Number of CPU cores: {num_cores}\")\n",
    "        \n",
    "        # Eseguiamo il preprocessing in parallelo\n",
    "        recipe_instances = Parallel(n_jobs=num_cores)(\n",
    "            delayed(process_recipe)(row) for row in tqdm(reader, desc=\"Processing recipes\", unit=\"recipes\")\n",
    "        )\n",
    "\n",
    "    return recipe_instances"
   ],
   "id": "5e8da04f0289a7e3",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T09:43:56.234137Z",
     "start_time": "2024-10-09T09:43:54.454974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create text list for dataset\n",
    "# https://www.kaggle.com/datasets/shuyangli94/food-com-recipes-and-user-interactions/data\n",
    "#recipe_list = load_preprocess_raw_data(\"dataset/RAW_merged.csv\")\n",
    "recipe_list = load_preprocess_raw_data_parallel(\"dataset/RAW_merged_top_smallest.csv\")\n",
    "recipe_list = recipe_list[:100]\n",
    "\n",
    "train_list, test_list = np.split(recipe_list, [int(.8 * len(recipe_list))])\n",
    "print('\\nNumber of train data: ', len(train_list))\n",
    "print('Number of test data: ', len(test_list))"
   ],
   "id": "7305fcc41d562385",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing recipes: 100%|██████████| 6010/6010 [00:01<00:00, 5643.26recipes/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of train data:  80\n",
      "Number of test data:  20\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T09:48:56.080013Z",
     "start_time": "2024-10-09T09:48:56.078142Z"
    }
   },
   "cell_type": "code",
   "source": "print(train_list[25])",
   "id": "c2ec262f1e1647a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BOS] [INGREDIENTS] cooking spray, sweet potato, salt, kosher salt, oil, sesame seed, oori paste, pepper flake [TECHNIQUES] bake, pour [STEPS] preheat oven to 375 degrees. line small, rimmed baking sheet with foil. spray with cooking spray. add cubed sweet potatoes, tandoori paste, sesame seeds, veg oil, 1/2 teaspoon salt, and red pepper flakes to bowl. stir until the sweet potatoes are well coated. pour onto the prepared baking sheet separate into a single layer. bake 20 minutes on bottom shelf. remove from oven with spatula turn over stir the sweet potatoes. place bake into the oven for additional 15-20 minutes. watch closely. they may need to be moved to top shelf. potatoes should begin to crisp and not be too dark. remove from oven. sprinkle with reserved 1/2 teaspoon of kosher salt [EOS]\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:26:20.522253Z",
     "start_time": "2024-10-09T07:26:20.129027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the GPT tokenizer.\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name, bos_token='[BOS]', eos_token='[EOS]', pad_token='[PAD]')\n",
    "# add special tokens for title, ingredients and instruction seperator\n",
    "special_tokens_dict = {'additional_special_tokens': ['[INGREDIENTS]', '[TECHNIQUES]', '[STEPS]']} # '[INGR]', '[STEP]'\n",
    "# check the number of special tokens\n",
    "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "print('We have added', num_added_toks, 'tokens')"
   ],
   "id": "94f53b4d8b82cb3d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have added 3 tokens\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:26:20.534191Z",
     "start_time": "2024-10-09T07:26:20.531938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Verifica gli ID dei token speciali\n",
    "special_tokens = ['[BOS]', '[EOS]', '[PAD]', '[INGREDIENTS]', '[TECHNIQUES]', '[STEPS]'] # '[INGR]'\n",
    "for token in special_tokens:\n",
    "    token_id = tokenizer.convert_tokens_to_ids(token)\n",
    "    print(f\"Token: {token}, ID: {token_id}\")"
   ],
   "id": "bf990733c71b6569",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: [BOS], ID: 50257\n",
      "Token: [EOS], ID: 50258\n",
      "Token: [PAD], ID: 50259\n",
      "Token: [INGREDIENTS], ID: 50260\n",
      "Token: [TECHNIQUES], ID: 50261\n",
      "Token: [STEPS], ID: 50262\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:26:20.583792Z",
     "start_time": "2024-10-09T07:26:20.560682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Esempio di testi\n",
    "texts = [\n",
    "    train_list[0]\n",
    "]\n",
    "\n",
    "# Tokenizzazione\n",
    "encodings = tokenizer.batch_encode_plus(\n",
    "    texts,\n",
    "    truncation=True,\n",
    "    max_length=320,\n",
    "    padding='max_length',\n",
    "    return_tensors='pt',\n",
    "    add_special_tokens=True  # Assicurati che i token speciali siano inclusi\n",
    ")\n",
    "\n",
    "# Visualizza gli input_ids e attention_mask\n",
    "print(\"Input IDs:\")\n",
    "print(encodings['input_ids'])\n",
    "print(\"\\nAttention Mask:\")\n",
    "print(encodings['attention_mask'])"
   ],
   "id": "c64c7c9f25db5f5f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs:\n",
      "tensor([[50257,   220, 50260,   537,   659,    11, 37792,    11, 13135,    11,\n",
      "         21772,  3056,    11,  8268,    11,  9267, 24240,   220, 50261, 20667,\n",
      "            11, 29901,    11,  1667,  4559,    11, 32857,    11, 12153,   220,\n",
      "         50262,  5022,   477,  9391,  1978,   290,   900,   319,  3753, 26547,\n",
      "         10491,    11,   262,  8268,   481,  2222,   503,   262, 13135,   286,\n",
      "           262, 23972,    11,  6938,   290,   751,   517,  1622,   654,   284,\n",
      "           534,  2614,  6938,    11,   345,   460,   779,  4713, 37792,   393,\n",
      "         23751,  1030,    78,   611,  9871,   837,   655,  3505,   284, 20720,\n",
      "         32566,   290,   779,   257,  1310,  1342,   621, 16577,    11,  3544,\n",
      "          1058,  4691,   351,  2048,   597,  9799,   355,   257,  1735,    11,\n",
      "           319,  1353,   286,   257,  4077, 20698,    11,   779,   355,   257,\n",
      "         34366,   329,   865,   385,  2395, 25854,  1377,   655, 30506, 23972,\n",
      "          2427,   286, 49289,    11,   779,   329,  1451,   260,   325, 20698,\n",
      "          1377,   751, 26790, 45019,  6941,  3019, 45494,   290,   345,   705,\n",
      "           260,  1760,    11,   423,   617, 39191, 13135,  1058,  1295,   617,\n",
      "         26790,  9015, 17515,   290,  1667,  4559,   625,  1755,   837,   788,\n",
      "          7773,  4781,   262,  9015,   290,  2952,   473,   315,   606,  1566,\n",
      "          1760,    11,   751,  5637, 13135,   290, 23972,   837, 20667,   329,\n",
      "           352,    12,    17,  2431,   290,   788,   751, 15847,  3112,   710,\n",
      "         26296,   837, 12153,   837,   290, 32857,   329,   642,    12,    21,\n",
      "          2431,    11, 13135,  3544,  1058,   345,   460, 32349,   262,  7559,\n",
      "          1667,   259,   671, 10148,   351,   649, 23972,    11,   655,   751,\n",
      "           617,   517, 26790, 23972,   284,   262, 13135,   290,  1309,  1650,\n",
      "           329,   546,  1160,  2431,    11,   393,   779,   262, 13135,   290,\n",
      "          1667,  4559,  5351,  5321,  9015,  9296, 13417,   287, 30500,   837,\n",
      "         29901,   290,  4691,   393, 16416,  9015,   290,  1353,   257,  1275,\n",
      "         18964, 20698,   351,   340,   220, 50258, 50259, 50259, 50259, 50259,\n",
      "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
      "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
      "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
      "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259,\n",
      "         50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259, 50259]])\n",
      "\n",
      "Attention Mask:\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:26:20.598717Z",
     "start_time": "2024-10-09T07:26:20.595013Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Decodifica dei token\n",
    "decoded_inputs = [tokenizer.decode(ids, skip_special_tokens=False) for ids in encodings['input_ids']]\n",
    "for i, decoded in enumerate(decoded_inputs):\n",
    "    print(f\"Decoded Input {i}: {decoded}\")"
   ],
   "id": "7c18a81d35858df6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded Input 0: [BOS]  [INGREDIENTS]  clove, basil, juice, virgin oil, salt, rom tomato  [TECHNIQUES]  boil, grill, marinate, simmer, toss  [STEPS]  mix all ingredients together and set on counter stirring occasionally, the salt will bring out the juice of the tomatoes, taste and add more seasonings to your personal taste, you can use fresh basil or oregano if preferred, just remember to chopped finely and use a little less than dried, uses : serve with almost any meal as a side, on top of a green salad, use as a topping for bruschetta -- just chop tomatoes instead of slicing, use for caprese salad -- add sliced buffalo mozzarella and you're done, have some leftover juice : place some sliced chicken breasts and marinate over night, then carefully remove the chicken and quickly saut them until done, add remaining juice and tomatoes, boil for 1-2 minutes and then add cooked penne pasta, toss, and simmer for 5-6 minutes, juice uses : you can reuse the `` marinade '' with new tomatoes, just add some more sliced tomatoes to the juice and let sit for about 20 minutes, or use the juice and marinate boneless chicken breast overnight in refrigerator, grill and serve or slice chicken and top a caesar salad with it [EOS][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:26:20.690460Z",
     "start_time": "2024-10-09T07:26:20.630171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lengths = [len(tokenizer.encode(recipe)) for recipe in recipe_list]\n",
    "max_length_in_data = max(lengths)\n",
    "avg_length_in_data = sum(lengths) / len(lengths)\n",
    "print(f\"Lunghezza massima: {max_length_in_data}, Lunghezza media: {avg_length_in_data}\")\n",
    "\n",
    "# Lunghezza massima: 312, Lunghezza media: 136.59567387687187"
   ],
   "id": "28e471a9fc239fee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lunghezza massima: 294, Lunghezza media: 138.17\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:26:20.714410Z",
     "start_time": "2024-10-09T07:26:20.711410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GPT2Dataset(Dataset):\n",
    "    def __init__(self, txt_list, tokenizer, max_length=320):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.texts = [text.lower() for text in txt_list]  # Preprocess texts to lowercase\n",
    "        \n",
    "        # Tokenize all texts in a batch\n",
    "        encodings = tokenizer.batch_encode_plus(\n",
    "            self.texts,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors='pt',\n",
    "            add_special_tokens=True\n",
    "        )\n",
    "        \n",
    "        self.input_ids = encodings['input_ids']\n",
    "        self.attn_masks = encodings['attention_mask']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attn_masks[idx]"
   ],
   "id": "78bf90f4f0831e0a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:26:20.768784Z",
     "start_time": "2024-10-09T07:26:20.727623Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = GPT2Dataset(train_list, tokenizer, max_length=320)\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ],
   "id": "7161f97045a959b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   64 training samples\n",
      "   16 validation samples\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:26:20.786479Z",
     "start_time": "2024-10-09T07:26:20.783794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create the DataLoaders for our training and validation datasets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,  # The training samples.\n",
    "    sampler=RandomSampler(train_dataset),  # Select batches randomly\n",
    "    batch_size=batch_size  # Trains with this batch size.\n",
    ")\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "    val_dataset,  # The validation samples.\n",
    "    sampler=SequentialSampler(val_dataset),  # Pull out batches sequentially.\n",
    "    batch_size=batch_size  # Evaluate with this batch size.\n",
    ")"
   ],
   "id": "33c8951c033ef8d4",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:26:25.874325Z",
     "start_time": "2024-10-09T07:26:20.798246Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Carica il modello\n",
    "# I'm not really doing anything with the config buheret\n",
    "pretrained = False\n",
    "try:\n",
    "    configuration = GPT2Config.from_pretrained(model_name, output_hidden_states=False)\n",
    "    model = GPT2LMHeadModel.from_pretrained(save_model, config=configuration, ignore_mismatched_sizes=True)\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(save_model)\n",
    "    \n",
    "    checkpoint = torch.load(f\"{save_model}_checkpoint.pth\")\n",
    "    pretrained = True\n",
    "except:\n",
    "    configuration = GPT2Config.from_pretrained(model_name, output_hidden_states=False)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name, config=configuration)\n",
    "    \n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                              lr=learning_rate,\n",
    "                              eps=epsilon\n",
    "                              )\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "print('Total number of steps: ', total_steps)\n",
    "\n",
    "warmup_steps = int(0.05 * total_steps) # 5% del totale degli step\n",
    "# Create the learning rate scheduler.\n",
    "# This changes the learning rate as the training loop progresses\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=warmup_steps,\n",
    "                                            num_training_steps=total_steps)\n",
    "start_epoch = 0\n",
    "loss = 9999999999\n",
    "\n",
    "if(pretrained):\n",
    "    # Ripristina il modello, l'ottimizzatore e lo scheduler\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    \n",
    "    # Imposta l'epoca da cui riprendere\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    loss = checkpoint['loss']\n",
    "    print(f\"Resuming training from epoch {start_epoch}\")\n",
    "\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "if device == \"cuda\":\n",
    "    torch.cuda.manual_seed_all(seed_val)"
   ],
   "id": "3dcdc139a16bf4c1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2LMHeadModel were not initialized from the model checkpoint at models/topsmallest_epochs and are newly initialized because the shapes did not match:\n",
      "- transformer.wte.weight: found shape torch.Size([50263, 768]) in the checkpoint and torch.Size([50257, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of steps:  80\n",
      "Resuming training from epoch 5\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:26:26.329776Z",
     "start_time": "2024-10-09T07:26:26.321385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "training_stats = []\n",
    "print(\"Currently using device type: \", device)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch_i in range(start_epoch, epochs):\n",
    "\n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    total_train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    loop = tqdm(train_dataloader, leave=True)\n",
    "    for step, batch in enumerate(loop):\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[0].to(device)\n",
    "        b_masks = batch[1].to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        outputs = model(b_input_ids,\n",
    "                        labels=b_labels,\n",
    "                        attention_mask=b_masks\n",
    "                        )\n",
    "\n",
    "        loss = outputs[0]\n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        total_train_loss += batch_loss\n",
    "        losses.append(batch_loss)\n",
    "\n",
    "        # Get sample every x batches.\n",
    "        if step % sample_every == 0 and not step == 0:\n",
    "            print('Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.'.format(step, len(train_dataloader), batch_loss))\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if step % save_every == 0:\n",
    "            model.save_pretrained(save_model)\n",
    "            torch.save({\n",
    "                'epoch': epoch_i,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'loss': loss,\n",
    "            }, f\"{save_model}_checkpoint.pth\")\n",
    "\n",
    "        loop.set_postfix(loss=batch_loss)\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "\n",
    "    # Calculate perplexity.\n",
    "    losses = torch.tensor(losses)\n",
    "    train_perplexity = math.exp(torch.mean(losses))\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Perplexity: {0:.2f}\".format(train_perplexity))\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[0].to(device)\n",
    "        b_masks = batch[1].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(b_input_ids,\n",
    "                            attention_mask=b_masks,\n",
    "                            labels=b_labels)\n",
    "\n",
    "            loss = outputs[0]\n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        losses.append(batch_loss)\n",
    "        total_eval_loss += batch_loss\n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "\n",
    "    # Calculate perplexity.\n",
    "    losses = torch.tensor(losses)\n",
    "    val_perplexity = math.exp(torch.mean(losses))\n",
    "\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation perplexity: {0:.2f}\".format(val_perplexity))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Training Perplexity': train_perplexity,\n",
    "            'Valid. Perplexity': val_perplexity,\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    break\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ],
   "id": "c9378deeb812b50f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently using device type:  cpu\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:26:26.446067Z",
     "start_time": "2024-10-09T07:26:26.335569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(epoch_i)\n",
    "print(loss)"
   ],
   "id": "7823fc66c97276f1",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epoch_i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[18], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mepoch_i\u001B[49m)\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(loss)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'epoch_i' is not defined"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T07:26:26.454340Z",
     "start_time": "2024-10-08T09:30:05.592939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Salva il modello\n",
    "if(start_epoch < epochs):\n",
    "    model.save_pretrained(save_model)\n",
    "    tokenizer.save_pretrained(save_model)\n",
    "    \n",
    "    # Salva lo stato dell'ottimizzatore e dello scheduler\n",
    "    torch.save({\n",
    "        'epoch': epoch_i,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'loss': loss,\n",
    "    }, f\"{save_model}_checkpoint.pth\")\n",
    "else:\n",
    "    print(\"Modello già salvato\")"
   ],
   "id": "b6b677c0bd507384",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modello già salvato\n"
     ]
    }
   ],
   "execution_count": 281
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
