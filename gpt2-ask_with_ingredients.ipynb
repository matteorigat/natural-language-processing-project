{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Imports",
   "id": "6962d319c068d488"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T17:35:17.811485Z",
     "start_time": "2025-05-05T17:35:07.494271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import ast\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle # <-- Added\n",
    "import os     # <-- Added\n",
    "import nltk   # <-- Added\n",
    "from nltk.corpus import stopwords # <-- Added\n",
    "from nltk import WordNetLemmatizer, word_tokenize, pos_tag # <-- Added\n",
    "from gensim.models import Word2Vec # <-- Added\n",
    "\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, BertModel, BertTokenizer\n",
    "from rouge import Rouge\n",
    "from sklearn.metrics.pairwise import cosine_similarity # <-- Already present, but needed by predict_cooking_methods\n",
    "from sklearn.preprocessing import normalize # <-- Added for predict_cooking_methods\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # <-- Already present\n",
    "\n",
    "# Setup tqdm for pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "print(\"Setting up NLTK...\")\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet.zip')\n",
    "    nltk.data.find('corpora/stopwords.zip')\n",
    "    nltk.data.find('tokenizers/punkt.zip')\n",
    "    nltk.data.find('taggers/averaged_perceptron_tagger.zip')\n",
    "    print(\"NLTK data found.\")\n",
    "except nltk.downloader.DownloadError:\n",
    "    print(\"Downloading necessary NLTK data...\")\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "    print(\"NLTK data download complete.\")\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(\"NLTK components initialized.\")"
   ],
   "id": "28850d92a6d06a99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up NLTK...\n",
      "NLTK data found.\n",
      "NLTK components initialized.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 2. Constants and Model Loading (GPT-2, BERT, Word2Vec)\n",
   "id": "68512bf58b170881"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T17:35:21.512889Z",
     "start_time": "2025-05-05T17:35:17.818464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- GPT-2 Constants and Loading ---\n",
    "SAVED_MODEL_PATH = \"models/colab_model_ingredients_epochs_3\"\n",
    "BASE_MODEL_NAME = \"gpt2\"\n",
    "DATASET_PATH = \"dataset/RAW_merged.csv\"\n",
    "DATASET_SAMPLE_FRACTION = 1.0 # Use 1.0 for full dataset, < 1.0 for sampling\n",
    "BERT_MODEL_NAME = 'bert-base-uncased'\n",
    "TOP_K_EVALUATION = 5\n",
    "W2V_MODEL_PATH = \"models/word2vec_ingredients_techniques.model\" # <-- Added\n",
    "TECHNIQUES_VECTORS_PATH = \"models/techniques_vectors.pkl\" # <-- Added\n",
    "W2V_PREDICTION_TOP_N = 3 # <-- Added: How many techniques to predict\n",
    "\n",
    "print(\"Loading GPT-2 tokenizer...\")\n",
    "tokenizer_gpt = GPT2Tokenizer.from_pretrained(BASE_MODEL_NAME, bos_token='[BOS]', eos_token='[EOS]', pad_token='[PAD]')\n",
    "special_tokens_dict = {'additional_special_tokens': ['[INGREDIENTS]', '[TECHNIQUES]', '[STEPS]']}\n",
    "num_added_toks = tokenizer_gpt.add_special_tokens(special_tokens_dict)\n",
    "print(f'Added {num_added_toks} special tokens: {tokenizer_gpt.additional_special_tokens}')\n",
    "\n",
    "print(f\"Loading fine-tuned GPT-2 model from: {SAVED_MODEL_PATH}\")\n",
    "model_gpt = GPT2LMHeadModel.from_pretrained(SAVED_MODEL_PATH)\n",
    "model_gpt.resize_token_embeddings(len(tokenizer_gpt))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_gpt.to(device)\n",
    "model_gpt.eval()\n",
    "print(f\"GPT-2 model loaded to: {device}\")\n",
    "\n",
    "# --- BERT Model Loading ---\n",
    "print(f\"Loading BERT tokenizer: {BERT_MODEL_NAME}\")\n",
    "tokenizer_bert = BertTokenizer.from_pretrained(BERT_MODEL_NAME)\n",
    "print(f\"Loading BERT model: {BERT_MODEL_NAME}\")\n",
    "model_bert = BertModel.from_pretrained(BERT_MODEL_NAME)\n",
    "model_bert.to(device)\n",
    "model_bert.eval()\n",
    "print(\"BERT model loaded.\")\n",
    "\n",
    "# --- Word2Vec Model and Techniques Vectors Loading (Added) ---\n",
    "print(\"Loading Word2Vec model and techniques vectors...\")\n",
    "if not os.path.exists(W2V_MODEL_PATH):\n",
    "    raise FileNotFoundError(f\"Word2Vec model file not found at: {W2V_MODEL_PATH}\")\n",
    "if not os.path.exists(TECHNIQUES_VECTORS_PATH):\n",
    "    raise FileNotFoundError(f\"Techniques vectors file not found at: {TECHNIQUES_VECTORS_PATH}\")\n",
    "\n",
    "model_w2v = Word2Vec.load(W2V_MODEL_PATH)\n",
    "print(\"Word2Vec model loaded.\")\n",
    "with open(TECHNIQUES_VECTORS_PATH, 'rb') as f:\n",
    "    techniques_vectors_dict = pickle.load(f)\n",
    "print(\"Techniques vectors loaded.\")\n",
    "\n",
    "# --- ROUGE Initializer ---\n",
    "rouge = Rouge()\n",
    "print(\"ROUGE initialized.\")"
   ],
   "id": "876023c9e06900e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GPT-2 tokenizer...\n",
      "Added 3 special tokens: ['[INGREDIENTS]', '[TECHNIQUES]', '[STEPS]']\n",
      "Loading fine-tuned GPT-2 model from: models/colab_model_ingredients_epochs_3\n",
      "GPT-2 model loaded to: cpu\n",
      "Loading BERT tokenizer: bert-base-uncased\n",
      "Loading BERT model: bert-base-uncased\n",
      "BERT model loaded.\n",
      "Loading Word2Vec model and techniques vectors...\n",
      "Word2Vec model loaded.\n",
      "Techniques vectors loaded.\n",
      "ROUGE initialized.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 3. Recipe Generation Function (GPT-2)",
   "id": "d04f5c7c112ac813"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T17:35:21.545019Z",
     "start_time": "2025-05-05T17:35:21.539919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_recipe(ingredients, techniques, model, tokenizer, max_length=820, temperature=0.7, top_k=50, top_p=0.9, num_beams=3, no_repeat_ngram_size=3, repetition_penalty=1.2):\n",
    "    # Ensure techniques is a string, handle empty list case from prediction\n",
    "    techniques_str = techniques if isinstance(techniques, str) else \", \".join(techniques)\n",
    "    if not techniques_str: # Handle case where no techniques were predicted or provided\n",
    "        print(\"Warning: No techniques provided or predicted. Generating without [TECHNIQUES] marker.\")\n",
    "        input_text = f'[BOS][INGREDIENTS]{ingredients}[TECHNIQUES][STEPS]' # Still include marker for structure\n",
    "    else:\n",
    "        input_text = f'[BOS][INGREDIENTS]{ingredients}[TECHNIQUES]{techniques_str}[STEPS]'\n",
    "\n",
    "    input_ids = tokenizer(input_text, return_tensors='pt').input_ids.to(device)\n",
    "    print(f\"Input Text for GPT-2: {input_text}\") # Debug print\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids,\n",
    "            max_length=max_length,\n",
    "            temperature=temperature,\n",
    "            top_k=top_k,\n",
    "            top_p=top_p,\n",
    "            num_beams=num_beams,\n",
    "            no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "            num_return_sequences=1,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            do_sample=True, # Keep True if you want sampling with beams\n",
    "            repetition_penalty=repetition_penalty\n",
    "        )\n",
    "\n",
    "    recipe = tokenizer.decode(output[0], skip_special_tokens=False)\n",
    "\n",
    "    # Normalize special tokens just in case\n",
    "    recipe = recipe.replace('[bos]', '[BOS]').replace('[ingredients]', '[INGREDIENTS]').replace('[techniques]', '[TECHNIQUES]').replace('[steps]', '[STEPS]').replace('[eos]', '[EOS]').replace('[pad]', '[PAD]')\n",
    "\n",
    "    # Clean up endings more robustly\n",
    "    recipe = recipe.split('[EOS]', 1)[0] + '[EOS]' if '[EOS]' in recipe else recipe\n",
    "    recipe = recipe.split('[PAD]', 1)[0] if '[PAD]' in recipe else recipe\n",
    "\n",
    "    return recipe"
   ],
   "id": "33aaed7468744af3",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 4. Highlighting Utility Function",
   "id": "3fa46fe19b93ef8e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T17:35:21.555982Z",
     "start_time": "2025-05-05T17:35:21.552784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. Highlighting Utility Function\n",
    "\n",
    "def print_highlighted(recipe_text, ingredients_str, techniques_str):\n",
    "    highlighted_recipe = recipe_text\n",
    "\n",
    "    # Convert techniques list to string if necessary for highlighting\n",
    "    if isinstance(techniques_str, list):\n",
    "        techniques_str = \", \".join(techniques_str)\n",
    "\n",
    "    # Highlight Ingredients (Red)\n",
    "    if ingredients_str:\n",
    "        # Split, strip, filter empty, sort by length descending\n",
    "        ingredients_list = sorted(\n",
    "            [ing.strip().lower() for ing in ingredients_str.split(',') if ing.strip()],\n",
    "            key=len, reverse=True\n",
    "        )\n",
    "        for ingredient in ingredients_list:\n",
    "            # Use word boundary for more precise matching, ignore case\n",
    "            pattern = r'\\b' + re.escape(ingredient) + r'\\b'\n",
    "            highlighted_recipe = re.sub(\n",
    "                pattern,\n",
    "                lambda match: f'\\033[91m{match.group(0)}\\033[0m', # Red\n",
    "                highlighted_recipe,\n",
    "                flags=re.IGNORECASE\n",
    "            )\n",
    "\n",
    "    # Highlight Techniques (Green)\n",
    "    if techniques_str:\n",
    "        # Split, strip, filter empty, sort by length descending\n",
    "        techniques_list = sorted(\n",
    "            [tech.strip().lower() for tech in techniques_str.split(',') if tech.strip()],\n",
    "            key=len, reverse=True\n",
    "        )\n",
    "        for technique in techniques_list:\n",
    "            # Use word boundary at start, allow common verb endings, then boundary\n",
    "            # e.g., matches 'dice', 'diced', 'dices', 'dicing' but not 'undice'\n",
    "            pattern = r'\\b' + re.escape(technique) + r'(?:d|ed|s|ing)?\\b'\n",
    "            highlighted_recipe = re.sub(\n",
    "                pattern,\n",
    "                lambda match: f'\\033[92m{match.group(0)}\\033[0m', # Green\n",
    "                highlighted_recipe,\n",
    "                flags=re.IGNORECASE\n",
    "            )\n",
    "\n",
    "    print(highlighted_recipe)"
   ],
   "id": "26139b4e28bdc041",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5. Utility Functions: Extractors and Word2Vec Predictor",
   "id": "8bb384c181082c3a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T17:35:21.590287Z",
     "start_time": "2025-05-05T17:35:21.581222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Existing Extractors ---\n",
    "def extract_ingredients(recipe_text):\n",
    "    start_marker = \"[INGREDIENTS]\"\n",
    "    end_marker_1 = \"[TECHNIQUES]\"\n",
    "    end_marker_2 = \"[STEPS]\" # Should cover cases where TECHNIQUES is missing\n",
    "\n",
    "    start_index = recipe_text.find(start_marker)\n",
    "    if start_index == -1: return \"\"\n",
    "    content_start_index = start_index + len(start_marker)\n",
    "\n",
    "    # Find the first occurrence of either end marker after [INGREDIENTS]\n",
    "    end_index_1 = recipe_text.find(end_marker_1, content_start_index)\n",
    "    end_index_2 = recipe_text.find(end_marker_2, content_start_index)\n",
    "\n",
    "    valid_end_indices = [idx for idx in [end_index_1, end_index_2] if idx != -1]\n",
    "\n",
    "    if not valid_end_indices:\n",
    "        end_index = len(recipe_text) # Go to the end if neither marker is found\n",
    "    else:\n",
    "        end_index = min(valid_end_indices)\n",
    "\n",
    "    return recipe_text[content_start_index:end_index].strip()\n",
    "\n",
    "def extract_steps(recipe_text):\n",
    "    try:\n",
    "        start_marker = \"[STEPS]\"\n",
    "        # Use rfind to get the LAST occurrence, handling potential model errors\n",
    "        start_index = recipe_text.rfind(start_marker)\n",
    "        if start_index == -1: return \"\"\n",
    "\n",
    "        content_start_index = start_index + len(start_marker)\n",
    "        end_marker_eos = \"[EOS]\"\n",
    "        end_marker_pad = \"[PAD]\" # Less common, but good to check\n",
    "\n",
    "        # Search only in the substring *after* the last [STEPS] marker\n",
    "        substring_after_last_steps = recipe_text[content_start_index:]\n",
    "        end_index_eos_rel = substring_after_last_steps.find(end_marker_eos)\n",
    "        end_index_pad_rel = substring_after_last_steps.find(end_marker_pad)\n",
    "\n",
    "        # Calculate absolute indices\n",
    "        end_index_eos = content_start_index + end_index_eos_rel if end_index_eos_rel != -1 else -1\n",
    "        end_index_pad = content_start_index + end_index_pad_rel if end_index_pad_rel != -1 else -1\n",
    "\n",
    "        # Find the first valid end marker\n",
    "        valid_end_indices = [idx for idx in [end_index_eos, end_index_pad] if idx != -1]\n",
    "\n",
    "        if not valid_end_indices:\n",
    "            end_index = len(recipe_text) # Go to the end if no marker found\n",
    "        else:\n",
    "            end_index = min(valid_end_indices)\n",
    "\n",
    "        steps_text = recipe_text[content_start_index:end_index].strip()\n",
    "        # Simple cleanup: remove potential leading/trailing list chars if any\n",
    "        steps_text = steps_text.strip(\"[]' \")\n",
    "        return steps_text\n",
    "    except Exception as e:\n",
    "        # print(f\"Error during step extraction: {e}\") # Optional logging\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "# --- Word2Vec Prediction Functions (Added/Copied from Script 1) ---\n",
    "def preprocess_ingredients(ingredients_list_input): # Takes a list of strings\n",
    "    processed_ingredients = []\n",
    "    regex = re.compile('[^a-zA-Z ]')\n",
    "    # Using global lemmatizer and stop_words defined in Section 1.5\n",
    "\n",
    "    # POS tags that represent nouns\n",
    "    noun_tags = {'NN', 'NNS', 'NNP', 'NNPS'} # Use a set for faster lookups\n",
    "\n",
    "    for ingr in ingredients_list_input:\n",
    "        ingr = regex.sub(' ', ingr.lower()).strip()\n",
    "        # Handle 'and' splitting if needed, though often better handled by POS tagging if structure is complex\n",
    "        components = [comp.strip() for comp in ingr.split(' and ')] # Split on ' and '\n",
    "\n",
    "        for comp in components:\n",
    "            if not comp: continue # Skip empty components\n",
    "\n",
    "            tokens = word_tokenize(comp)\n",
    "            tagged_tokens = pos_tag(tokens)\n",
    "\n",
    "            # Extract sequences of nouns (potential compound nouns or single nouns)\n",
    "            current_noun_phrase = []\n",
    "            for word, tag in tagged_tokens:\n",
    "                lemma = lemmatizer.lemmatize(word.strip())\n",
    "                if len(lemma) > 2 and lemma not in stop_words:\n",
    "                    if tag in noun_tags:\n",
    "                        current_noun_phrase.append(lemma)\n",
    "                    else:\n",
    "                        # If we encounter a non-noun and have a current noun phrase, add it\n",
    "                        if current_noun_phrase:\n",
    "                            processed_ingredients.append(\" \".join(current_noun_phrase))\n",
    "                            current_noun_phrase = []\n",
    "                else: # Word is too short or a stopword, breaks the noun phrase\n",
    "                    if current_noun_phrase:\n",
    "                        processed_ingredients.append(\" \".join(current_noun_phrase))\n",
    "                        current_noun_phrase = []\n",
    "\n",
    "\n",
    "            # Add any remaining noun phrase at the end of the component\n",
    "            if current_noun_phrase:\n",
    "                processed_ingredients.append(\" \".join(current_noun_phrase))\n",
    "\n",
    "    # Return unique, non-empty, reasonably long processed ingredients/phrases\n",
    "    return list(set(item for item in processed_ingredients if item and len(item) > 2))\n",
    "\n",
    "\n",
    "def predict_cooking_methods(ingredients_str_input, techniques_vectors, w2v_model, top_n=3):\n",
    "    # Split input string into a list and strip whitespace\n",
    "    ingredients = [ingredient.strip() for ingredient in ingredients_str_input.split(\",\") if ingredient.strip()]\n",
    "    if not ingredients:\n",
    "        print(\"Input ingredients list is empty after splitting/stripping.\")\n",
    "        return [] # Return empty list for no ingredients\n",
    "\n",
    "    print(f\"Original ingredients for prediction: {ingredients}\")\n",
    "    ingredient_list = preprocess_ingredients(ingredients) # Pass the list\n",
    "    print(f\"Processed ingredients for prediction: {ingredient_list}\")\n",
    "\n",
    "    # Get vectors for ingredients found in the model's vocabulary\n",
    "    ingredient_vectors = [w2v_model.wv[ingredient] for ingredient in ingredient_list if ingredient in w2v_model.wv]\n",
    "\n",
    "    if not ingredient_vectors: # Check if the list is empty\n",
    "        print(\"Warning: None of the processed ingredients were found in the Word2Vec model vocabulary.\")\n",
    "        # Return an empty list instead of an error string\n",
    "        return []\n",
    "\n",
    "    # Calculate the average vector and normalize\n",
    "    avg_ingredient_vector = np.mean(ingredient_vectors, axis=0).reshape(1, -1)\n",
    "    normalized_avg_ingredient_vector = normalize(avg_ingredient_vector)\n",
    "\n",
    "    # Calculate cosine similarities with normalized technique vectors\n",
    "    similarities = {}\n",
    "    for technique, technique_vector in techniques_vectors.items():\n",
    "        # Ensure technique_vector is a numpy array and reshape, then normalize\n",
    "        technique_vector_np = np.array(technique_vector).reshape(1, -1)\n",
    "        normalized_technique_vector = normalize(technique_vector_np)\n",
    "        # Calculate cosine similarity\n",
    "        similarity_score = cosine_similarity(normalized_avg_ingredient_vector, normalized_technique_vector)[0][0]\n",
    "        similarities[technique] = similarity_score\n",
    "\n",
    "    # Sort techniques by similarity score in descending order\n",
    "    sorted_techniques = sorted(similarities, key=similarities.get, reverse=True)\n",
    "\n",
    "    # Return the top_n techniques or an empty list if none found\n",
    "    return sorted_techniques[:top_n] if sorted_techniques else []"
   ],
   "id": "6f9eb0c2c9351fb8",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6. Similarity Calculation Functions (TF-IDF, BERT)",
   "id": "d57a7830d1ca4aff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T17:35:21.611681Z",
     "start_time": "2025-05-05T17:35:21.607134Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Existing Similarity Functions ---\n",
    "def calculate_ingredient_similarity(ingredients1_str, ingredients2_str):\n",
    "    if not ingredients1_str or not ingredients2_str: return 0.0\n",
    "    try:\n",
    "        # Simple TF-IDF Cosine Similarity\n",
    "        vectorizer = TfidfVectorizer().fit([ingredients1_str, ingredients2_str])\n",
    "        vectors = vectorizer.transform([ingredients1_str, ingredients2_str]).toarray()\n",
    "        # Handle empty vocabulary case\n",
    "        if vectors.shape[1] == 0: return 0.0\n",
    "        # Calculate cosine similarity\n",
    "        cosine_sim = cosine_similarity(vectors)\n",
    "        # Return similarity between the two documents (off-diagonal element)\n",
    "        return max(0.0, min(1.0, cosine_sim[0, 1])) # Clamp between 0 and 1\n",
    "    except ValueError: # Catch potential errors during vectorization\n",
    "        # print(f\"TF-IDF Error for:\\n1: {ingredients1_str}\\n2: {ingredients2_str}\") # Optional Debug\n",
    "        return 0.0\n",
    "    except Exception as e:\n",
    "        # print(f\"Unexpected TF-IDF Error: {e}\") # Optional Debug\n",
    "        return 0.0\n",
    "\n",
    "def get_bert_embedding(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors='pt', max_length=512, truncation=True, padding='max_length') # Use max_length padding\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # Mean pooling of the last hidden state, considering attention mask\n",
    "        last_hidden_state = outputs.last_hidden_state\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "        sum_embeddings = torch.sum(last_hidden_state * mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9) # Avoid division by zero\n",
    "        pooled_embedding = sum_embeddings / sum_mask\n",
    "    return pooled_embedding.cpu().numpy() # Return numpy array\n",
    "\n",
    "def calculate_bert_similarity(text1, text2, model, tokenizer):\n",
    "    if not text1 or not text2: return 0.0\n",
    "    try:\n",
    "        embedding1 = get_bert_embedding(text1, model, tokenizer)\n",
    "        embedding2 = get_bert_embedding(text2, model, tokenizer)\n",
    "        # Calculate cosine similarity using sklearn function\n",
    "        similarity = cosine_similarity(embedding1, embedding2).item()\n",
    "        # Clamp the result between 0 and 1\n",
    "        return max(0.0, min(1.0, similarity))\n",
    "    except Exception as e:\n",
    "        # print(f\"BERT Similarity Error: {e}\") # Optional logging\n",
    "        return 0.0\n"
   ],
   "id": "bf05f9a16da28c4e",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 7. Main Evaluation Function",
   "id": "b08947be38a9cef8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T17:35:21.635493Z",
     "start_time": "2025-05-05T17:35:21.628922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_generated_recipe_by_ingredients(\n",
    "    generated_recipe_full_string,\n",
    "    real_recipes_data_list,\n",
    "    model_bert,\n",
    "    tokenizer_bert,\n",
    "    rouge,\n",
    "    top_k=5,\n",
    "    ):\n",
    "\n",
    "    if not real_recipes_data_list:\n",
    "        print(\"Error: Real recipes data list is empty for evaluation.\")\n",
    "        return [] # Return empty list on error\n",
    "\n",
    "    # Minimal check for expected keys in the first item (if list is not empty)\n",
    "    if real_recipes_data_list and not all(k in real_recipes_data_list[0] for k in ['ingredients_string', 'recipe_string', 'avg_rating']):\n",
    "         print(\"Warning: Real recipe data dictionaries might be missing required keys ('ingredients_string', 'recipe_string', 'avg_rating').\")\n",
    "\n",
    "    generated_ingredients = extract_ingredients(generated_recipe_full_string)\n",
    "    generated_steps = extract_steps(generated_recipe_full_string)\n",
    "\n",
    "    if not generated_steps:\n",
    "        print(\"Error: Could not extract steps from the generated recipe. Evaluation aborted.\")\n",
    "        return [] # Cannot evaluate without steps\n",
    "    if not generated_ingredients:\n",
    "        print(\"Warning: Could not extract ingredients from generated recipe. Ingredient similarity calculation might be affected.\")\n",
    "\n",
    "    ingredient_similarities = []\n",
    "    # Use leave=False for cleaner progress bar in loops within functions\n",
    "    pbar_ing = tqdm(real_recipes_data_list, desc=\"Evaluating: Ingredient Sim\", leave=False)\n",
    "    for i, real_recipe_data in enumerate(pbar_ing):\n",
    "        real_ingredients = real_recipe_data.get('ingredients_string', '')\n",
    "        similarity = calculate_ingredient_similarity(generated_ingredients, real_ingredients)\n",
    "        ingredient_similarities.append({'real_recipe_data': real_recipe_data, 'ingredient_similarity': similarity})\n",
    "\n",
    "    # Sort by ingredient similarity descending\n",
    "    ingredient_similarities.sort(key=lambda x: x['ingredient_similarity'], reverse=True)\n",
    "    # Select top K candidates\n",
    "    top_k_candidates = ingredient_similarities[:top_k]\n",
    "\n",
    "    if not top_k_candidates:\n",
    "        print(\"No similar real recipes found based on ingredients after sorting.\")\n",
    "        return [] # No candidates to evaluate further\n",
    "\n",
    "    evaluation_results = []\n",
    "\n",
    "    pbar_scores = tqdm(top_k_candidates, desc=\"Evaluating: Scores\", leave=False)\n",
    "    for candidate in pbar_scores:\n",
    "        real_data = candidate['real_recipe_data']\n",
    "        ing_sim = candidate['ingredient_similarity']\n",
    "        # Extract steps from the real recipe string stored in the dictionary\n",
    "        real_steps = extract_steps(real_data.get('recipe_string', '')) # Use extractor here too\n",
    "\n",
    "        if not real_steps:\n",
    "            continue # Skip if real steps cannot be extracted\n",
    "\n",
    "        # Calculate ROUGE-L F1\n",
    "        rouge_l_f1 = 0.0\n",
    "        try:\n",
    "            # Ensure both strings are non-empty before calculating ROUGE\n",
    "            if generated_steps and real_steps:\n",
    "                rouge_scores = rouge.get_scores(generated_steps, real_steps)\n",
    "                # Check if scores were returned and contain the expected structure\n",
    "                if rouge_scores and isinstance(rouge_scores, list) and len(rouge_scores) > 0:\n",
    "                    rouge_l_f1 = rouge_scores[0].get('rouge-l', {}).get('f', 0.0)\n",
    "        except Exception as e:\n",
    "             print(f\"DROUGE calculation failed: {e}\")\n",
    "\n",
    "\n",
    "        # Calculate BERT Similarity\n",
    "        bert_similarity = 0.0\n",
    "        try:\n",
    "             # Ensure both strings are non-empty\n",
    "             if generated_steps and real_steps:\n",
    "                 bert_similarity = calculate_bert_similarity(generated_steps, real_steps, model_bert, tokenizer_bert)\n",
    "        except Exception as e:\n",
    "             print(f\"BERT similarity calculation failed: {e}\")\n",
    "\n",
    "        # Get real average rating, handle potential missing key or non-numeric value\n",
    "        real_rating = real_data.get('avg_rating', np.nan)\n",
    "        if not isinstance(real_rating, (int, float)):\n",
    "            real_rating = np.nan # Ensure it's NaN if not numeric\n",
    "\n",
    "        evaluation_results.append({\n",
    "            'real_recipe_data': real_data,\n",
    "            'ingredient_similarity': ing_sim,\n",
    "            'rouge_l_f1': rouge_l_f1,\n",
    "            'bert_similarity': bert_similarity,\n",
    "            'real_avg_rating': real_rating\n",
    "        })\n",
    "\n",
    "    return evaluation_results\n"
   ],
   "id": "5ae8169a9c60d910",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 8. Load and Prepare Real Recipe Data",
   "id": "42bb476c646d397e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T17:35:30.283641Z",
     "start_time": "2025-05-05T17:35:21.658436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_preprocess_raw_data(raw_data_path):\n",
    "    recipes_data = []\n",
    "    print(f\"Loading data from: {raw_data_path}\")\n",
    "    try:\n",
    "        with open(raw_data_path, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f)\n",
    "            # Use tqdm here for progress on reading the CSV\n",
    "            for row in tqdm(reader, desc=\"Reading CSV\", unit=\" rows\"):\n",
    "                try:\n",
    "                    # Use .get() with defaults to avoid KeyError\n",
    "                    ingredients_raw = row.get('ingredients', '[]')\n",
    "                    instructions_raw = row.get('steps', '[]')\n",
    "                    techniques_raw = row.get('techniques_list', '[]')\n",
    "                    recipe_id = row.get('id', 'N/A')\n",
    "\n",
    "                    # Safely evaluate lists, default to empty list on error\n",
    "                    try: ingredients_list = ast.literal_eval(ingredients_raw) if isinstance(ingredients_raw, str) and ingredients_raw.startswith('[') else []\n",
    "                    except (ValueError, SyntaxError): ingredients_list = []\n",
    "                    try: instructions_list = ast.literal_eval(instructions_raw) if isinstance(instructions_raw, str) and instructions_raw.startswith('[') else []\n",
    "                    except (ValueError, SyntaxError): instructions_list = []\n",
    "                    try: techniques_list = ast.literal_eval(techniques_raw) if isinstance(techniques_raw, str) and techniques_raw.startswith('[') else []\n",
    "                    except (ValueError, SyntaxError): techniques_list = []\n",
    "\n",
    "                    # Join lists into strings, handle non-string items just in case\n",
    "                    ingredients_str = \", \".join(filter(None, map(str, ingredients_list))).lower()\n",
    "                    instructions_str = \" \".join(filter(None, map(str, instructions_list))).lower() # Join steps with space\n",
    "                    techniques_str = \", \".join(filter(None, map(str, techniques_list))).lower()\n",
    "\n",
    "                    # Process rating\n",
    "                    avg_rating = np.nan\n",
    "                    try:\n",
    "                        # Prioritize 'avg_rating', fall back to 'rating'\n",
    "                        rating_val = row.get('avg_rating', row.get('rating', None))\n",
    "                        if rating_val is not None and rating_val != '':\n",
    "                            avg_rating = float(rating_val)\n",
    "                    except (ValueError, TypeError):\n",
    "                        pass # Keep avg_rating as np.nan if conversion fails\n",
    "\n",
    "                    # Basic validation: need ingredients and instructions\n",
    "                    if ingredients_str and instructions_str:\n",
    "                        # Construct the full recipe string for potential reference/debugging\n",
    "                        # Always include markers for consistency\n",
    "                        if techniques_str:\n",
    "                            recipe_instance_string = f'[BOS][INGREDIENTS]{ingredients_str}[TECHNIQUES]{techniques_str}[STEPS]{instructions_str}[EOS]'\n",
    "                        else:\n",
    "                            recipe_instance_string = f'[BOS][INGREDIENTS]{ingredients_str}[TECHNIQUES][STEPS]{instructions_str}[EOS]' # Empty techniques marker\n",
    "\n",
    "                        recipes_data.append({\n",
    "                            'id': recipe_id, # Keep ID for reference\n",
    "                            'recipe_string': recipe_instance_string, # Full string representation\n",
    "                            'ingredients_string': ingredients_str,   # Comma-separated ingredients\n",
    "                            'techniques_string': techniques_str,     # Comma-separated techniques\n",
    "                            'steps_string': instructions_str,        # Space-joined steps\n",
    "                            'avg_rating': avg_rating                 # Float rating or NaN\n",
    "                        })\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing row ID {row.get('id', 'N/A')}: {e}. Row data: {row}\")\n",
    "                    continue\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Dataset file not found at: {raw_data_path}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR reading CSV file '{raw_data_path}': {e}\")\n",
    "        return []\n",
    "\n",
    "    print(f\"Loaded {len(recipes_data)} valid recipes.\")\n",
    "    return recipes_data\n",
    "\n",
    "# --- Load and Sample Data ---\n",
    "full_recipes_data_list = load_preprocess_raw_data(DATASET_PATH)\n",
    "\n",
    "sampled_recipes_data_list = []\n",
    "if full_recipes_data_list:\n",
    "    # Decide whether to sample or use the full dataset\n",
    "    if 0.0 < DATASET_SAMPLE_FRACTION < 1.0:\n",
    "        sample_size = max(1, int(DATASET_SAMPLE_FRACTION * len(full_recipes_data_list)))\n",
    "        print(f\"Sampling {sample_size} recipes ({DATASET_SAMPLE_FRACTION*100:.1f}% of {len(full_recipes_data_list)})...\")\n",
    "        # Ensure sample size doesn't exceed population size (edge case)\n",
    "        sample_size = min(sample_size, len(full_recipes_data_list))\n",
    "        sampled_recipes_data_list = random.sample(full_recipes_data_list, sample_size)\n",
    "    elif DATASET_SAMPLE_FRACTION >= 1.0:\n",
    "         print(f\"Using the full loaded dataset ({len(full_recipes_data_list)} recipes) for evaluation.\")\n",
    "         sampled_recipes_data_list = full_recipes_data_list\n",
    "    else: # Handle fraction <= 0\n",
    "         print(\"Warning: DATASET_SAMPLE_FRACTION is zero or negative. No recipes selected for evaluation.\")\n",
    "\n",
    "    print(f\"Number of real recipes available for evaluation: {len(sampled_recipes_data_list)}\")\n",
    "else:\n",
    "    print(\"ERROR: No recipes loaded. Evaluation cannot proceed.\")"
   ],
   "id": "7323929f12c17b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: dataset/RAW_merged.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reading CSV: 0 rows [00:00, ? rows/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c317078f471b4c8886f5e960733f8ce9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 178265 valid recipes.\n",
      "Using the full loaded dataset (178265 recipes) for evaluation.\n",
      "Number of real recipes available for evaluation: 178265\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 9. Execution: Generation and Evaluation (Using Predicted Techniques)",
   "id": "3139345623fee8fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-05T19:08:21.798066Z",
     "start_time": "2025-05-05T19:08:11.218008Z"
    }
   },
   "cell_type": "code",
   "source": [
    " # 9. Execution: Generation and Evaluation (Using Predicted Techniques)\n",
    "\n",
    "ingredients = \"salt, water, salame, icecream, oregano, chicken, tomato, cheese, pasta, garlic, onion\"\n",
    "\n",
    "print(f\"Input Ingredients: {ingredients}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- Predict Techniques using Word2Vec (MODIFIED SECTION) ---\n",
    "print(\"Predicting techniques using Word2Vec...\")\n",
    "predicted_techniques_list = predict_cooking_methods(\n",
    "    ingredients_str_input=ingredients,\n",
    "    techniques_vectors=techniques_vectors_dict,\n",
    "    w2v_model=model_w2v,\n",
    "    top_n=W2V_PREDICTION_TOP_N\n",
    ")\n",
    "\n",
    "# Convert list to comma-separated string for generation input\n",
    "techniques = \", \".join(predicted_techniques_list)\n",
    "\n",
    "if techniques:\n",
    "    print(f\"Predicted Techniques (Top {W2V_PREDICTION_TOP_N}): {techniques}\")\n",
    "else:\n",
    "    print(\"No relevant techniques predicted by Word2Vec.\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "\n",
    "# --- Generate Recipe using Predicted Techniques ---\n",
    "print(\"Generating recipe with GPT-2...\")\n",
    "generated_recipe_output = generate_recipe(\n",
    "    ingredients=ingredients,\n",
    "    techniques=techniques, # Use the predicted techniques string\n",
    "    model=model_gpt,\n",
    "    tokenizer=tokenizer_gpt,\n",
    "    # You can adjust generation parameters here if needed\n",
    "    # temperature=0.75, top_k=60, top_p=0.95, num_beams=4, repetition_penalty=1.3\n",
    ")\n",
    "print(\"\\n\" + \"-\" * 30 + \"\\n\")\n",
    "# --- Print Generated Recipe with Highlighting ---\n",
    "print(\"Generated Recipe:\")\n",
    "# Pass the original ingredients and the *predicted* techniques string for highlighting\n",
    "print_highlighted(generated_recipe_output, ingredients, techniques)\n",
    "print(\"\\n\" + \"-\" * 30 + \"\\n\")\n",
    "\n",
    "\n",
    "# --- Evaluate Generated Recipe ---\n",
    "if sampled_recipes_data_list:\n",
    "    print(f\"\\nStarting evaluation against {len(sampled_recipes_data_list)} real recipes (Comparing with Top {TOP_K_EVALUATION} similar)...\")\n",
    "\n",
    "    # Pass the full generated text to the evaluation function\n",
    "    evaluation_results = evaluate_generated_recipe_by_ingredients(\n",
    "        generated_recipe_full_string=generated_recipe_output,\n",
    "        real_recipes_data_list=sampled_recipes_data_list,\n",
    "        model_bert=model_bert,\n",
    "        tokenizer_bert=tokenizer_bert,\n",
    "        rouge=rouge,\n",
    "        top_k=TOP_K_EVALUATION,\n",
    "        debug=False # Set to True for more verbose evaluation steps\n",
    "    )\n",
    "\n",
    "    # --- Display Evaluation Results ---\n",
    "    if evaluation_results: # Check if evaluation returned any results\n",
    "        print(f\"\\n--- Evaluation Results (Comparing against Top {len(evaluation_results)} Real Recipes Based on Ingredient Similarity) ---\")\n",
    "\n",
    "        valid_ratings = [] # To calculate average rating of benchmarks\n",
    "        all_rouge_l = []\n",
    "        all_bert_sim = []\n",
    "        all_ing_sim = []\n",
    "\n",
    "        for i, result in enumerate(evaluation_results):\n",
    "            print(f\"\\n--- Real Benchmark #{i + 1} ---\")\n",
    "            real_data = result.get('real_recipe_data', {})\n",
    "            real_rating = result.get('real_avg_rating', np.nan)\n",
    "            ing_sim = result.get('ingredient_similarity', 0.0)\n",
    "            rouge_l = result.get('rouge_l_f1', 0.0)\n",
    "            bert_sim = result.get('bert_similarity', 0.0)\n",
    "\n",
    "            print(f\"Ingredient Similarity: {ing_sim:.4f}\")\n",
    "            all_ing_sim.append(ing_sim)\n",
    "\n",
    "            if not np.isnan(real_rating):\n",
    "                 print(f\"Real Rating: {real_rating:.2f} stars\")\n",
    "                 valid_ratings.append(real_rating)\n",
    "            else:\n",
    "                 print(\"Real Recipe Avg Rating: N/A\")\n",
    "\n",
    "            print(f\"ROUGE-L F1: {rouge_l:.4f}\")\n",
    "            all_rouge_l.append(rouge_l)\n",
    "            print(f\"BERT Similarity: {bert_sim:.4f}\")\n",
    "            all_bert_sim.append(bert_sim)\n",
    "\n",
    "            # Display the text of the real benchmark recipe for comparison\n",
    "            print(\"\\nReal Recipe Text (Benchmark):\")\n",
    "            # Highlight the REAL recipe using the INPUT ingredients/techniques for consistency\n",
    "            print_highlighted(real_data.get('recipe_string', 'N/A'), ingredients, techniques)\n",
    "            print(\"-\" * 20) # Separator between benchmark recipes\n",
    "\n",
    "        # Calculate and print average scores\n",
    "        avg_rouge = np.nanmean(all_rouge_l) if all_rouge_l else 0.0\n",
    "        avg_bert_sim = np.nanmean(all_bert_sim) if all_bert_sim else 0.0\n",
    "        avg_ing_sim = np.nanmean(all_ing_sim) if all_ing_sim else 0.0\n",
    "        avg_real_rating = np.nanmean(valid_ratings) if valid_ratings else np.nan\n",
    "\n",
    "        print(\"\\n--- Average Scores Across Top Benchmarks ---\")\n",
    "        print(f\"Avg Ingredient Similarity: {avg_ing_sim:.4f}\")\n",
    "        if not np.isnan(avg_real_rating):\n",
    "             print(f\"Avg Rating of these Real Benchmarks: {avg_real_rating:.2f} stars (based on {len(valid_ratings)} rated recipes)\")\n",
    "        else:\n",
    "             print(\"Avg Rating of these Real Benchmarks: N/A\")\n",
    "        print(f\"Avg ROUGE-L F1: {avg_rouge:.4f}\")\n",
    "        print(f\"Avg BERT Similarity: {avg_bert_sim:.4f}\")\n",
    "    else:\n",
    "        print(\"\\nEvaluation completed, but no benchmark recipes were found suitable for comparison (e.g., due to extraction errors or zero similarity).\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nEvaluation skipped: No real recipe data loaded or sampled.\")\n",
    "\n",
    "print(\"\\nExecution complete.\")"
   ],
   "id": "98dd20b869dcf652",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Ingredients: salt, water, salame, icecream, oregano, chicken, tomato, cheese, pasta, garlic, onion\n",
      "------------------------------\n",
      "Predicting techniques using Word2Vec...\n",
      "Original ingredients for prediction: ['salt', 'water', 'salame', 'icecream', 'oregano', 'chicken', 'tomato', 'cheese', 'pasta', 'garlic', 'onion']\n",
      "Processed ingredients for prediction: ['water', 'oregano', 'onion', 'icecream', 'tomato', 'chicken', 'salt', 'pasta', 'garlic', 'salame', 'cheese']\n",
      "Predicted Techniques (Top 3): parboil, dice, saute\n",
      "------------------------------\n",
      "Generating recipe with GPT-2...\n",
      "Input Text for GPT-2: [BOS][INGREDIENTS]salt, water, salame, icecream, oregano, chicken, tomato, cheese, pasta, garlic, onion[TECHNIQUES]parboil, dice, saute[STEPS]\n",
      "\n",
      "------------------------------\n",
      "\n",
      "Generated Recipe:\n",
      "[BOS] [INGREDIENTS] \u001B[91msalt\u001B[0m, \u001B[91mwater\u001B[0m, \u001B[91msalame\u001B[0m, \u001B[91micecream\u001B[0m, \u001B[91moregano\u001B[0m, \u001B[91mchicken\u001B[0m, \u001B[91mtomato\u001B[0m, \u001B[91mcheese\u001B[0m, \u001B[91mpasta\u001B[0m, \u001B[91mgarlic\u001B[0m, \u001B[91monion\u001B[0m [TECHNIQUES] \u001B[92mparboil\u001B[0m, \u001B[92mdice\u001B[0m, \u001B[92msaute\u001B[0m [STEPS], oil [TECHNIQUES] boil, combine, drain, simmer, skillet [STEPS] cook \u001B[91mpasta\u001B[0m according to package directions. meanwhile, in a large skillet, heat oil over medium-high heat. add \u001B[92mdiced\u001B[0m \u001B[91mchicken\u001B[0m and \u001B[92msaute\u001B[0m until \u001B[91mchicken\u001B[0m is no longer pink, about 5 minutes. add \u001B[91mgarlic\u001B[0m and \u001B[91monion\u001B[0m and cook until \u001B[91monion\u001B[0m is tender, about 3 minutes. stir in \u001B[92mdiced\u001B[0m tomatoes, \u001B[91msalt\u001B[0m, and pepper and bring to a boil. reduce heat to low, cover, and simmer for 15 minutes or until \u001B[91mpasta\u001B[0m is tender. drain \u001B[91mpasta\u001B[0m and return to pot. add \u001B[91mchicken\u001B[0m mixture to skillet and stir to combine. add \u001B[91msalame\u001B[0m and parmesan \u001B[91mcheese\u001B[0m and stir until combined. serve over hot cooked \u001B[91mpasta\u001B[0m. garnish with fresh oreganos and serve with additional parmesian \u001B[91mcheese\u001B[0m if desired [EOS]\n",
      "\n",
      "------------------------------\n",
      "\n",
      "\n",
      "Starting evaluation against 178265 real recipes (Comparing with Top 5 similar)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 50\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mStarting evaluation against \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(sampled_recipes_data_list)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m real recipes (Comparing with Top \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mTOP_K_EVALUATION\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m similar)...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     49\u001B[0m \u001B[38;5;66;03m# Pass the full generated text to the evaluation function\u001B[39;00m\n\u001B[0;32m---> 50\u001B[0m evaluation_results \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_generated_recipe_by_ingredients\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     51\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgenerated_recipe_full_string\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgenerated_recipe_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     52\u001B[0m \u001B[43m    \u001B[49m\u001B[43mreal_recipes_data_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msampled_recipes_data_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     53\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_bert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_bert\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtokenizer_bert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtokenizer_bert\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrouge\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrouge\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtop_k\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mTOP_K_EVALUATION\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     57\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdebug\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# Set to True for more verbose evaluation steps\u001B[39;49;00m\n\u001B[1;32m     58\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;66;03m# --- Display Evaluation Results ---\u001B[39;00m\n\u001B[1;32m     61\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m evaluation_results: \u001B[38;5;66;03m# Check if evaluation returned any results\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[8], line 34\u001B[0m, in \u001B[0;36mevaluate_generated_recipe_by_ingredients\u001B[0;34m(generated_recipe_full_string, real_recipes_data_list, model_bert, tokenizer_bert, rouge, top_k, debug)\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, real_recipe_data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(pbar_ing):\n\u001B[1;32m     33\u001B[0m     real_ingredients \u001B[38;5;241m=\u001B[39m real_recipe_data\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mingredients_string\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m---> 34\u001B[0m     similarity \u001B[38;5;241m=\u001B[39m \u001B[43mcalculate_ingredient_similarity\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgenerated_ingredients\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreal_ingredients\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m     ingredient_similarities\u001B[38;5;241m.\u001B[39mappend({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreal_recipe_data\u001B[39m\u001B[38;5;124m'\u001B[39m: real_recipe_data, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mingredient_similarity\u001B[39m\u001B[38;5;124m'\u001B[39m: similarity})\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m debug \u001B[38;5;129;01mand\u001B[39;00m i \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m100\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m: pbar_ing\u001B[38;5;241m.\u001B[39mset_postfix({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mProcessed\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(real_recipes_data_list)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m})\n",
      "Cell \u001B[0;32mIn[7], line 7\u001B[0m, in \u001B[0;36mcalculate_ingredient_similarity\u001B[0;34m(ingredients1_str, ingredients2_str)\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;66;03m# Simple TF-IDF Cosine Similarity\u001B[39;00m\n\u001B[1;32m      6\u001B[0m     vectorizer \u001B[38;5;241m=\u001B[39m TfidfVectorizer()\u001B[38;5;241m.\u001B[39mfit([ingredients1_str, ingredients2_str])\n\u001B[0;32m----> 7\u001B[0m     vectors \u001B[38;5;241m=\u001B[39m \u001B[43mvectorizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mingredients1_str\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mingredients2_str\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtoarray()\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;66;03m# Handle empty vocabulary case\u001B[39;00m\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m vectors\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m: \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m0.0\u001B[39m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:2163\u001B[0m, in \u001B[0;36mTfidfVectorizer.transform\u001B[0;34m(self, raw_documents)\u001B[0m\n\u001B[1;32m   2160\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m, msg\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe TF-IDF vectorizer is not fitted\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   2162\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mtransform(raw_documents)\n\u001B[0;32m-> 2163\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tfidf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:1726\u001B[0m, in \u001B[0;36mTfidfTransformer.transform\u001B[0;34m(self, X, copy)\u001B[0m\n\u001B[1;32m   1720\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_idf:\n\u001B[1;32m   1721\u001B[0m     \u001B[38;5;66;03m# idf_ being a property, the automatic attributes detection\u001B[39;00m\n\u001B[1;32m   1722\u001B[0m     \u001B[38;5;66;03m# does not work as usual and we need to specify the attribute\u001B[39;00m\n\u001B[1;32m   1723\u001B[0m     \u001B[38;5;66;03m# name:\u001B[39;00m\n\u001B[1;32m   1724\u001B[0m     check_is_fitted(\u001B[38;5;28mself\u001B[39m, attributes\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124midf_\u001B[39m\u001B[38;5;124m\"\u001B[39m], msg\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124midf vector is not fitted\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 1726\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[43mX\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m@\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_idf_diag\u001B[49m\n\u001B[1;32m   1728\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1729\u001B[0m     X \u001B[38;5;241m=\u001B[39m normalize(X, norm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnorm, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/scipy/sparse/_base.py:678\u001B[0m, in \u001B[0;36m_spbase.__matmul__\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m    675\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m isscalarlike(other):\n\u001B[1;32m    676\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mScalar operands are not allowed, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    677\u001B[0m                      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muse \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m*\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m instead\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 678\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mul_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/scipy/sparse/_base.py:589\u001B[0m, in \u001B[0;36m_spbase._mul_dispatch\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m    587\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m!=\u001B[39m other\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]:\n\u001B[1;32m    588\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdimension mismatch\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 589\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mul_sparse_matrix\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    591\u001B[0m \u001B[38;5;66;03m# If it's a list or whatever, treat it like an array\u001B[39;00m\n\u001B[1;32m    592\u001B[0m other_a \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masanyarray(other)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.12.1/lib/python3.12/site-packages/scipy/sparse/_compressed.py:523\u001B[0m, in \u001B[0;36m_cs_matrix._mul_sparse_matrix\u001B[0;34m(self, other)\u001B[0m\n\u001B[1;32m    519\u001B[0m idx_dtype \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_index_dtype((\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindptr, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices,\n\u001B[1;32m    520\u001B[0m                              other\u001B[38;5;241m.\u001B[39mindptr, other\u001B[38;5;241m.\u001B[39mindices))\n\u001B[1;32m    522\u001B[0m fn \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(_sparsetools, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mformat \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_matmat_maxnnz\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m--> 523\u001B[0m nnz \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mM\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mN\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[43m         \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindptr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43midx_dtype\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    525\u001B[0m \u001B[43m         \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43midx_dtype\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    526\u001B[0m \u001B[43m         \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindptr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43midx_dtype\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[43m         \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43masarray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mother\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43midx_dtype\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    529\u001B[0m idx_dtype \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_index_dtype((\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindptr, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices,\n\u001B[1;32m    530\u001B[0m                              other\u001B[38;5;241m.\u001B[39mindptr, other\u001B[38;5;241m.\u001B[39mindices),\n\u001B[1;32m    531\u001B[0m                             maxval\u001B[38;5;241m=\u001B[39mnnz)\n\u001B[1;32m    533\u001B[0m indptr \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mempty(major_axis \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, dtype\u001B[38;5;241m=\u001B[39midx_dtype)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
